{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d50e16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os as os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from pygam import LinearGAM, s\n",
    "\n",
    "# from shapely.geometry import Point\n",
    "# from shapely.ops import unary_union\n",
    "# from dataclasses import dataclass, field\n",
    "# from typing_extensions import List, Dict, Tuple\n",
    "\n",
    "if 'scicore' in os.getcwd():\n",
    "    path = '/scicore/home/krysiak/hocrau00/ondemand/OptimalPV_RH'\n",
    "else:\n",
    "    path = os.getcwd().split('\\\\src')[0]\n",
    "    %load_ext rpy2.ipython\n",
    "\n",
    "os.chdir(path)\n",
    "from src.calibration_class import Calibration_Settings, Calibration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a68f42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dir_export_path_PY = 'c:/Models/OptimalPV_RH/data/calibration/calib_all_CH_bfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "189e0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "name_dir_export_path_R <- \"c:/Models/OptimalPV_RH/data/calibration/calib_all_CH_bfs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093c09c",
   "metadata": {},
   "source": [
    "### preprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b69ee2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    preprep_list = [\n",
    "        # Calibration_Settings(), \n",
    "\n",
    "        Calibration_Settings(\n",
    "            name_dir_export='calib_mini_debug',\n",
    "            name_preprep_subsen='bfs1201',\n",
    "            bfs_numbers=[1201,],\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False\n",
    "        ), \n",
    "        Calibration_Settings(\n",
    "            name_dir_export='calib_mini_debug',\n",
    "            name_preprep_subsen='bfs1205',\n",
    "            bfs_numbers=[1205,],\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False\n",
    "        ), \n",
    "        # Calibration_Settings(\n",
    "        #     name_dir_export='calib_mini_debug',\n",
    "        #     name_preprep_subsen='bfs96',\n",
    "        #     bfs_numbers=[96,],\n",
    "        #     rerun_import_and_preprp_data_TF = True,\n",
    "        #     export_gwr_ALL_building_gdf_TF = False\n",
    "        # ), \n",
    "        # Calibration_Settings(\n",
    "        #     name_dir_export='calib_mini_debug',\n",
    "        #     name_preprep_subsen='bfs1033',\n",
    "        #     bfs_numbers=[1033,],\n",
    "        #     rerun_import_and_preprp_data_TF = True,\n",
    "        #     export_gwr_ALL_building_gdf_TF = False\n",
    "        # ), \n",
    "    ]\n",
    "\n",
    "    for i_prep, prep_sett in enumerate(preprep_list):\n",
    "        print('')\n",
    "    #     preprep_class = Calibration(prep_sett)\n",
    "    #     preprep_class.import_and_preprep_data() if preprep_class.sett.rerun_import_and_preprp_data_TF else None\n",
    "\n",
    "    # preprep_class = Calibration(preprep_list[0])\n",
    "    # preprep_class.concatenate_prerep_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a99b6c",
   "metadata": {},
   "source": [
    "### concat preprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2e5f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "  START CALIBRATION: calib_all_CH_bfs\n",
      "  > name_preprep_subsen: preprep_class_default_sett\n",
      "  > name_calib_subscen: calib_class_default_sett\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calib_main_sett = Calibration_Settings(\n",
    "            name_dir_export='calib_all_CH_bfs',\n",
    "            scicore_concat_data_path = r'/scicore/home/krysiak/hocrau00/OptimalPV_RH/data/calibration/',\n",
    "            kt_numbers=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,], \n",
    "            # name_preprep_subsen=f'bfs{bfs_number}',\n",
    "            # bfs_numbers=[bfs_number,], \n",
    "            n_rows_import= None,\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False)\n",
    "calib_main = Calibration(calib_main_sett)\n",
    "# calib_main.concatenate_prerep_data()\n",
    "# calib_main.estimdf2_regression_instsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e84a8e",
   "metadata": {},
   "source": [
    "## approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524bbe33",
   "metadata": {},
   "source": [
    "### data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ebdb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weed out all inf or NaN values \n",
    "df = pd.read_csv(f'{name_dir_export_path_PY}/reg2_all_CH_bfs_df_approach2.csv')\n",
    "df = df.dropna(subset=['BFS_NUMMER', 'TotalPower', 'elecpri_Rp_kWh', 'pvtarif_Rp_kWh', 'north_max_flaeche', 'south_max_flaeche', 'east_max_flaeche', 'west_max_flaeche'])\n",
    "df.to_csv(f'{name_dir_export_path_PY}/reg2_all_CH_bfs_df_cleaned.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0a64b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: <class 'UnicodeDecodeError'> 'utf-8' codec can't decode byte 0xfc in position 27: invalid start byte <traceback object at 0x0000029B2CDFA380>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "if (!requireNamespace(\"readr\", quietly = TRUE)) install.packages(\"readr\")\n",
    "if (!requireNamespace(\"dplyr\", quietly = TRUE)) install.packages(\"dplyr\")\n",
    "if (!requireNamespace(\"fixest\", quietly = TRUE)) install.packages(\"fixest\")\n",
    "if (!requireNamespace(\"tibble\", quietly = TRUE)) install.packages(\"tibble\")\n",
    "if (!requireNamespace(\"jsonlite\", quietly = TRUE)) install.packages(\"jsonlite\")\n",
    "if (!requireNamespace(\"tidyr\", quietly = TRUE)) install.packages(\"tidyr\")\n",
    "if (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\n",
    "if (!requireNamespace(\"purr\", quietly = TRUE)) install.packages(\"purr\")\n",
    "if (!requireNamespace(\"tidyverse\", quietly = TRUE)) install.packages(\"tidyverse\")\n",
    "if (!requireNamespace(\"randomForest\", quietly = TRUE)) install.packages(\"randomForest\")\n",
    "\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "library(fixest)\n",
    "library(tibble)\n",
    "library(jsonlite)\n",
    "library(tidyr)\n",
    "library(ggplot2)\n",
    "library(purrr)\n",
    "library(tidyverse)\n",
    "library(randomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62b5e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 94433 Columns: 20\n",
      "-- Column specification --------------------------------------------------------\n",
      "Delimiter: \",\"\n",
      "dbl (20): EGID, year, BFS_NUMMER, xtf_id, n_DF_UID, GAREA, GBAUJ, GKLAS, GST...\n",
      "\n",
      "i Use `spec()` to retrieve the full column specification for this data.\n",
      "i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# train / test split-------------\n",
    "# train_test_split = 0.7\n",
    "\n",
    "# import -------------\n",
    "pq_files = list.files(name_dir_export_path_R, pattern = \".parquet\", full.names = TRUE)\n",
    "\n",
    "  df <- tibble(read_csv(paste0(name_dir_export_path_R, \"/reg2_all_CH_bfs_df_cleaned.csv\"), locale = locale(encoding = \"UTF-8\")))\n",
    "\n",
    "  df <- df %>% \n",
    "    mutate(\n",
    "      GBAUJ = as_factor(GBAUJ),\n",
    "      GKLAS = as_factor(GKLAS),\n",
    "      GSTAT = as_factor(GSTAT),\n",
    "      GWAERZH1 = as_factor(GWAERZH1),\n",
    "      GENH1 = as_factor(GENH1))\n",
    "\n",
    "  idx_heatpump <- df$GWAERZH1 %in% c('7410', '7411')\n",
    "  df$GWAERZH1_str <- 'no_heatpump'\n",
    "  df$GWAERZH1_str[idx_heatpump] <- 'heatpump'\n",
    "  df$GWAERZH1_str <- as_factor(df$GWAERZH1_str)\n",
    "\n",
    "\n",
    "  # split training & test data -------------\n",
    "  split_train_test <- function(df_func, df_sub_type, split_ratio = 0.7, seed = 42) {\n",
    "    set.seed(seed)\n",
    "    train_indices <- sample(1:nrow(df_func), size = split_ratio * nrow(df_func))\n",
    "    df_train_func <- df_func[train_indices, ]\n",
    "    df_test_func <- df_func[-train_indices, ]\n",
    "    \n",
    "    if (df_sub_type == \"train\"){\n",
    "      df_return = df_train_func\n",
    "    }\n",
    "    else if (df_sub_type == \"test\"){\n",
    "      df_return = df_test_func\n",
    "    }\n",
    "    else {\n",
    "      stop(\"df_sub_type must be either 'train' or 'test'\")\n",
    "    } \n",
    "    return(df_return)\n",
    "  }\n",
    "\n",
    "  df_train <- split_train_test(df, \"train\" )\n",
    "  df_test <-  split_train_test(df, \"test\"  )\n",
    "\n",
    "\n",
    "  # filter: only residential buildings -------------\n",
    "  idx_GKLAS_res3plus <- df$GKLAS %in% c(\"1110\", \"1121\", \"1122\")\n",
    "  df__res3plus <- df %>% filter(idx_GKLAS_res3plus)\n",
    "  df_train_res3plus <- split_train_test(df__res3plus, \"train\" )\n",
    "  df_test_res3plus <-  split_train_test(df__res3plus, \"test\"  )\n",
    "\n",
    "\n",
    "  idx_GKLAS_res1to2 <- df$GKLAS %in% c(\"1110\", \"1121\")\n",
    "  df__res1to2 <- df %>% filter(idx_GKLAS_res1to2)\n",
    "  df_train_res1to2 <- split_train_test(df__res1to2, \"train\" )\n",
    "  df_test_res1to2 <-  split_train_test(df__res1to2, \"test\"  )\n",
    "\n",
    "  idx_kwpmax20 <- df$TotalPower < 20\n",
    "  df__kwpmax20 <- df %>% filter(idx_kwpmax20 & idx_GKLAS_res1to2)\n",
    "  df_train_kwpmax20 <- split_train_test(df__kwpmax20, \"train\" )\n",
    "  df_test_kwpmax20 <-  split_train_test(df__kwpmax20, \"test\"  )\n",
    "\n",
    "\n",
    "  # export training & test data ------------ยง\n",
    "  write_csv(df_train, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_train.csv\"))\n",
    "  write_csv(df_test, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test.csv\"))\n",
    "\n",
    "  write_csv(df_train_res3plus,  paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_res3plus.csv\"))\n",
    "  write_csv(df_test_res3plus,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res3plus.csv\"))\n",
    "  write_csv(df_train_res1to2,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_res1to2.csv\"))\n",
    "  write_csv(df_test_res1to2,    paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res1to2.csv\" ))\n",
    "  write_csv(df_train_kwpmax20,  paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_kwpmax20.csv\"))\n",
    "  write_csv(df_test_kwpmax20,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_kwpmax20.csv\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d680b26",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54084fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "# fit regression model\n",
    "fe11 <- feols( TotalPower ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche, data = df_train )\n",
    "fe12 <- feols( TotalPower ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche | year, data = df_train    )\n",
    "\n",
    "fe13 <- feols( TotalPower ~\n",
    "    elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "    west_max_flaeche + south_max_flaeche + east_max_flaeche |\n",
    "    BFS_NUMMER,\n",
    "    data = df_train\n",
    "    )\n",
    "df_test$pred_fe13 <- predict(fe13, newdata = df_test)\n",
    "\n",
    "fe14 <- feols( TotalPower ~\n",
    "    elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "    west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "    BFS_NUMMER + year,\n",
    "    data = df_train\n",
    "    )\n",
    "df_test$pred_fe14 <- predict(fe14, newdata = df_test)\n",
    "\n",
    "fe21 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train\n",
    ")\n",
    "df_test$pred_fe21 <- predict(fe21, newdata = df_test)\n",
    "\n",
    "fe24a <- feols(log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh +west_max_flaeche + south_max_flaeche + east_max_flaeche, data = df_train)\n",
    "fe24b <- feols( log(TotalPower) ~  elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche |  year,  data = df_train )\n",
    "\n",
    "fe24c<- feols(\n",
    "    log(TotalPower) ~ \n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER, \n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe24c <- predict(fe24c, newdata = df_test)\n",
    "\n",
    "fe24d<- feols(\n",
    "    log(TotalPower) ~ \n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe24d <- predict(fe24d, newdata = df_test)\n",
    "\n",
    "fe25a<- feols(log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh +west_max_flaeche + south_max_flaeche + east_max_flaeche,data = df_train)\n",
    "fe25b<- feols( log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche |  year, data = df_train)\n",
    "fe25c<- feols(\n",
    "    log(TotalPower) ~\n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe25c <- predict(fe25c, newdata = df_test)\n",
    "\n",
    "fe25d<- feols(\n",
    "    log(TotalPower) ~\n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe25d <- predict(fe25d, newdata = df_test)\n",
    "\n",
    "fe26a <- feols( log(TotalPower) ~  elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) + pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + west_max_flaeche + I(west_max_flaeche^2) + south_max_flaeche + I(south_max_flaeche^2) + east_max_flaeche + I(east_max_flaeche^2), data = df_train)\n",
    "fe26b <- feols( log(TotalPower) ~  elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) + pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + west_max_flaeche + I(west_max_flaeche^2) + south_max_flaeche + I(south_max_flaeche^2) + east_max_flaeche + I(east_max_flaeche^2) | year, data = df_train )\n",
    "fe26c <- feols(\n",
    "    log(TotalPower) ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe26c <- predict(fe26c, newdata = df_test)\n",
    "\n",
    "fe26d <- feols(\n",
    "    log(TotalPower) ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe26d <- predict(fe26d, newdata = df_test)\n",
    "\n",
    "\n",
    "# only residential buildings of small size\n",
    "fe30 <-  feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train\n",
    ")\n",
    "df_test$pred_fe30 <- predict(fe30, newdata = df_test)\n",
    "\n",
    "fe31 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res3plus\n",
    ")\n",
    "df_test_res3plus$pred_fe31 <- predict(fe31, newdata = df_test_res3plus) \n",
    "\n",
    "fe32 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res1to2\n",
    ")\n",
    "df_test_res1to2$pred_fe32 <- predict(fe32, newdata = df_test_res1to2)\n",
    "\n",
    "fe40 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    FLAECHE_total + I(FLAECHE_total^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res3plus\n",
    ")\n",
    "df_test_res3plus$pred_fe40 <- predict(fe40, newdata = df_test_res3plus)\n",
    "\n",
    "fe41 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    FLAECHE_total + I(FLAECHE_total^2) |  \n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res1to2\n",
    ")\n",
    "df_test_res1to2$pred_fe41 <- predict(fe41, newdata = df_test_res1to2)\n",
    "\n",
    "\n",
    "write_csv(df_test, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test.csv\"))\n",
    "write_csv(df_test_res3plus, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res3plus.csv\"))\n",
    "write_csv(df_test_res1to2, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res1to2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c7b6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "fe_model_list <- list(\n",
    "  fe11 = fe11, fe12 = fe12, fe13 = fe13, fe14 = fe14, \n",
    "  fe21 = fe21, \n",
    "  # fe22 = fe22, fe23 = fe23,\n",
    "  fe24a = fe24a, fe24b = fe24b, fe24c = fe24c, fe24d = fe24d, \n",
    "  fe25a = fe25a, fe25b = fe25b, fe25c = fe25c, fe25d = fe25d,\n",
    "  fe26a = fe26a, fe26b = fe26b, fe26c = fe26c, fe26d = fe26d,\n",
    "  fe30 = fe30, fe31 = fe31,\n",
    "  fe40 = fe40, fe41 = fe41\n",
    ")\n",
    "\n",
    "# Export model info as a named list\n",
    "model_export <- lapply(fe_model_list, function(model) {\n",
    "  list(\n",
    "    comment = paste(deparse(formula(model)), collapse = \" \"),\n",
    "    coefficients = coef(model)\n",
    "  )\n",
    "})\n",
    "\n",
    "# Write JSON with model names as top-level keys\n",
    "write_json(\n",
    "  model_export,\n",
    "  path = file.path(getwd(), \"data/calibration/calib_all_CH_bfs/reg2_fe_model_coef.json\"),\n",
    "  pretty = TRUE,\n",
    "  auto_unbox = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcfc62",
   "metadata": {},
   "source": [
    "### ML random forest regression - full sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest_regression(rfr_mod_name, df_suffix, rfr_settings):\n",
    "\n",
    "    # import\n",
    "    df_train_rfr = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train{df_suffix}.csv')\n",
    "    df_test_rfr  = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv')\n",
    "\n",
    "\n",
    "    # transformations\n",
    "    # df_train_rfr = df_train_rfr.drop(columns=['EGID', 'xtf_id', 'n_DF_UID']).copy()\n",
    "    cols_dtypes_tupls = {\n",
    "        # 'year': 'int64',\n",
    "        'BFS_NUMMER': 'category',\n",
    "        'GAREA': 'float64',\n",
    "        # 'GBAUJ': 'int64',   \n",
    "        'GKLAS': 'category',\n",
    "        # 'GSTAT': 'category',\n",
    "        'GWAERZH1': 'category',\n",
    "        'GENH1': 'category',\n",
    "        'GWAERZH1_str': 'category',\n",
    "        # 'InitialPower': 'float64',\n",
    "        'TotalPower': 'float64',\n",
    "        'elecpri_Rp_kWh': 'float64',\n",
    "        'pvtarif_Rp_kWh': 'float64',\n",
    "        'FLAECHE_total': 'float64',\n",
    "        'east_max_flaeche': 'float64',\n",
    "        'west_max_flaeche': 'float64',\n",
    "        'north_max_flaeche': 'float64',\n",
    "        'south_max_flaeche': 'float64',\n",
    "    }\n",
    "    df_train_rfr = df_train_rfr[[col for col in cols_dtypes_tupls.keys() if col in df_train_rfr.columns]].copy()\n",
    "    df_test_rfr = df_test_rfr[[col for col in cols_dtypes_tupls.keys() if col in df_test_rfr.columns]].copy()\n",
    "\n",
    "    df_train_rfr = df_train_rfr.dropna().copy()\n",
    "    df_test_rfr = df_test_rfr.dropna().copy()\n",
    "\n",
    "\n",
    "    for col, dtype in cols_dtypes_tupls.items():\n",
    "        df_train_rfr[col] = df_train_rfr[col].astype(dtype)\n",
    "        df_test_rfr[col]  = df_test_rfr[col].astype(dtype)\n",
    "\n",
    "    X = df_train_rfr.drop(columns=['TotalPower', ])\n",
    "    y = df_train_rfr['TotalPower']\n",
    "\n",
    "    # encode categorical variables\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_Arry = encoder.fit_transform(X[cat_cols].astype(str))\n",
    "    encoded_df = pd.DataFrame(encoded_Arry, columns=encoder.get_feature_names_out(cat_cols))\n",
    "    X = pd.concat([X.drop(columns=cat_cols).reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "    # rf model\n",
    "    if rfr_settings['run_ML_rfr_TF']:\n",
    "        # rfr_model = RandomForestRegressor(\n",
    "        #     n_estimators   = rfr_settings['n_estimators'],\n",
    "        #     max_depth      = rfr_settings['max_depth'],\n",
    "        #     random_state   = rfr_settings['random_state'],\n",
    "        #     n_jobs         = rfr_settings['n_jobs'],\n",
    "        # )\n",
    "        # # cross validation\n",
    "        # kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        # cv_scores = cross_val_score(rfr_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "        # rfr_model.fit(X, y)\n",
    "\n",
    "        rfr_model = RandomForestRegressor(random_state = rfr_settings['random_state'])\n",
    "        param_grid = {\n",
    "            'n_estimators':      rfr_settings['n_estimators'],\n",
    "            'min_samples_split': rfr_settings['min_samples_split'],\n",
    "            'max_depth':         rfr_settings['max_depth'],\n",
    "        }\n",
    "            \n",
    "        grid_search = GridSearchCV(\n",
    "            rfr_model,\n",
    "            param_grid,\n",
    "            cv=rfr_settings['cross_validation'],\n",
    "            scoring='neg_mean_absolute_error',\n",
    "            n_jobs=rfr_settings['n_jobs'],\n",
    "            return_train_score=True,\n",
    "        )\n",
    "        grid_search.fit(X, y)\n",
    "        rfr_model = grid_search.best_estimator_\n",
    "\n",
    "        # save model\n",
    "        mod_path = f'{name_dir_export_path_PY}/reg2_{rfr_mod_name}_model.pkl'\n",
    "        joblib.dump(rfr_model, mod_path)\n",
    "\n",
    "\n",
    "    # prediction\n",
    "    if rfr_settings['run_ML_rfr_TF']:\n",
    "        X_test = df_test_rfr.drop(columns=['TotalPower', ])\n",
    "        encoded_test_array = encoder.transform(X_test[cat_cols].astype(str))\n",
    "        encoded_test_df = pd.DataFrame(encoded_test_array, columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "        X_test_final = pd.concat([X_test.drop(columns=cat_cols).reset_index(drop=True), encoded_test_df.reset_index(drop=True)], axis=1)\n",
    "        X_test_final = X_test_final[X.columns]\n",
    "\n",
    "        test_preds = rfr_model.predict(X_test_final)\n",
    "\n",
    "        df_test_rfr[f'pred_{rfr_mod_name}'] = test_preds\n",
    "\n",
    "    else: \n",
    "        df_test_rfr[f'pred_{rfr_mod_name}'] = np.zeros(df_test_rfr.shape[0])\n",
    "\n",
    "    df_test_rfr.to_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv', index=False)\n",
    "    del df_train_rfr, df_test_rfr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e88d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ML_rfr_TF = True\n",
    "rfr_settings = {\n",
    "    'comment_settings_RandomForestRegressor()': \n",
    "        \"\"\"\n",
    "        n_estimators:       Defines the number of decision trees in the Random Forest.\n",
    "        random_state=0:     Ensures the randomness in model training is controlled for reproducibility.\n",
    "        oob_score=True:     Enables out-of-bag scoring which evaluates the model's performance using data \n",
    "                            not seen by individual trees during training\n",
    "        max_depth:          The maximum depth of the tree. If None, then nodes are expanded until all \n",
    "                            leaves are pure or until all leaves contain less than min_samples_split \n",
    "                            samples\n",
    "\n",
    "    \"\"\",\n",
    "    'run_ML_rfr_TF':        True,\n",
    "    'random_state':         None,    # default: None  # | None,    \n",
    "    'n_jobs':               -1,      # default: None  # | -1,      \n",
    "    'cross_validation':     2, \n",
    "    'n_estimators':         [10, ]  ,    # default: 100   # | 1,       \n",
    "    'min_samples_split':    [5, ]    ,    # default: 2     # | 1000,    \n",
    "    'max_depth':            [6, ]   ,    # default: None  # | 3,       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61abb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_random_forest_regression(rfr_mod_name='local_nb_rfr1', df_suffix='',             rfr_settings=rfr_settings)\n",
    "run_random_forest_regression(rfr_mod_name='local_nb_rfr2_mini', df_suffix='_kwpmax20',    rfr_settings=rfr_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d8ee5",
   "metadata": {},
   "source": [
    "### GAM - Generalized Additive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "90521dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train.csv')\n",
    "df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "            'north_max_flaeche', 'south_max_flaeche',\n",
    "            'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "x_train = df_train[features].values\n",
    "y_train = df_train['TotalPower'].values\n",
    "\n",
    "x_test = df_test[features].values\n",
    "y_test = df_test['TotalPower'].values\n",
    "\n",
    "gam1 = LinearGAM(\n",
    "    s(0) + s(1) + s(2) + s(3) + s(4) + s(5)\n",
    ").fit(x_train, y_train)\n",
    "y_pred_gam1 = gam1.predict(x_train)\n",
    "df_test['pred_gam1'] = gam1.predict(x_test)\n",
    "\n",
    "# export coefs and df_test\n",
    "model_formula = \"TotalPower ~ s(elecpri_Rp_kWh) + s(pvtarif_Rp_kWh) + s(north_max_flaeche) + s(south_max_flaeche) + s(east_max_flaeche) + s(west_max_flaeche)\"\n",
    "coefficients = gam1.coef_.tolist()\n",
    "lambdas = list(gam1.lam)\n",
    "terms = [str(gam1.terms[i]) for i in range(len(gam1.terms))]\n",
    "reg2_gam_model_coef = {\n",
    "    \"comment\": model_formula,\n",
    "    \"coefficients\": coefficients,\n",
    "    \"lambdas\": lambdas,\n",
    "    \"terms\": terms\n",
    "}\n",
    "with open(f'{name_dir_export_path_PY}/reg2_gam_model_coef.json', 'w') as f:\n",
    "    json.dump(reg2_gam_model_coef, f, indent=4)\n",
    "\n",
    "df_test.to_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "41821458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_res1to2 =  pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train_res1to2.csv')\n",
    "df_test_res1to2 =   pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv' )\n",
    "\n",
    "features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "            'north_max_flaeche', 'south_max_flaeche',\n",
    "            'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "x_train = df_train_res1to2[features].values\n",
    "y_train = df_train_res1to2['TotalPower'].values\n",
    "\n",
    "x_test = df_test_res1to2[features].values\n",
    "y_test = df_test_res1to2['TotalPower'].values\n",
    "\n",
    "gam2 = LinearGAM(\n",
    "    s(0) + s(1) + s(2) + s(3) + s(4) + s(5)\n",
    ").fit(x_train, y_train)\n",
    "y_pred_gam2 = gam2.predict(x_train)\n",
    "df_test_res1to2['pred_gam2'] = gam2.predict(x_test)\n",
    "\n",
    "# export coefs and df_test\n",
    "model_formula = \"TotalPower ~ s(elecpri_Rp_kWh) + s(pvtarif_Rp_kWh) + s(north_max_flaeche) + s(south_max_flaeche) + s(east_max_flaeche) + s(west_max_flaeche)\"\n",
    "coefficients = gam2.coef_.tolist()\n",
    "lambdas = list(gam2.lam)\n",
    "terms = [str(gam2.terms[i]) for i in range(len(gam2.terms))]\n",
    "reg2_gam_model_coef = {\n",
    "    \"comment\": model_formula,\n",
    "    \"coefficients\": coefficients,\n",
    "    \"lambdas\": lambdas,\n",
    "    \"terms\": terms\n",
    "}\n",
    "with open(f'{name_dir_export_path_PY}/reg2_gam_model_coef.json', 'w') as f:\n",
    "    json.dump(reg2_gam_model_coef, f, indent=4)\n",
    "\n",
    "df_test_res1to2.to_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fd345",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cbee4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d144886",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['pred_rfr2']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14896\\3098278156.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     44\u001b[39m         df_import = pd.read_csv(\u001b[33mf'{name_dir_export_path_PY}/reg2_df_test_res3plus.csv'\u001b[39m)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m pred_col \u001b[38;5;28;01min\u001b[39;00m pred_cols_res1to2:\n\u001b[32m     46\u001b[39m         df_import = pd.read_csv(\u001b[33mf'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv'\u001b[39m)\n\u001b[32m     47\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     df_import = df_import.dropna(subset=[pred_col, \u001b[33m'TotalPower'\u001b[39m])\n\u001b[32m     49\u001b[39m     df_accu = df_import.replace([np.inf, -np.inf], np.nan).dropna(subset=[\u001b[33m'TotalPower'\u001b[39m, pred_col]).copy()\n\u001b[32m     50\u001b[39m \n\u001b[32m     51\u001b[39m     fig.add_trace(\n",
      "\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6666\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6667\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6668\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6669\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6670\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6671\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6672\u001b[39m \n\u001b[32m   6673\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['pred_rfr2']"
     ]
    }
   ],
   "source": [
    "# PREDICTION ACCURACY PLOTS\n",
    "\n",
    "    # 'pred_fe11', 'pred_fe12', \n",
    "    #  'pred_fe22', 'pred_fe23', \n",
    "    # 'pred_fe24a', 'pred_fe24b', \n",
    "    # 'pred_fe25a', 'pred_fe25b', \n",
    "    # 'pred_fe26a', 'pred_fe26b', \n",
    "pred_cols_reg = [\n",
    "    # 'pred_fe13', \n",
    "    # 'pred_fe14', \n",
    "    'pred_fe21',\n",
    "    # 'pred_fe24c','pred_fe24d', \n",
    "    # 'pred_fe25c', 'pred_fe25d',\n",
    "    # 'pred_fe26c', 'pred_fe26d',\n",
    "    # 'pred_gam1',\n",
    "    'pred_fe30',\n",
    "    'local_nb_rfr1',\n",
    "    'pred_rfr1',\n",
    "    ]\n",
    "pred_cols_res3plus = [\n",
    "    'pred_fe31', 'pred_fe40'\n",
    "    ]\n",
    "pred_cols_res1to2 = [\n",
    "    'pred_fe32', 'pred_fe41',\n",
    "    # 'pred_gam2',\n",
    "    'local_nb_rfr1',\n",
    "    'pred_rfr2',\n",
    "    ]  \n",
    "pre_cols_scicore = [\n",
    "    ]\n",
    "pred_cols = pred_cols_reg + pred_cols_res3plus + pred_cols_res1to2 + pre_cols_scicore\n",
    "\n",
    "\n",
    "# accuracy plot ------------\n",
    "\n",
    "ncols = 4\n",
    "nplots = len (pred_cols)\n",
    "nrows = math.ceil(nplots / ncols)\n",
    "fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=pred_cols, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "for i, pred_col in enumerate(pred_cols):\n",
    "    row = (i // ncols) + 1\n",
    "    col = (i % ncols) + 1\n",
    "\n",
    "    if pred_col in pred_cols_reg:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "    elif pred_col in pred_cols_res3plus:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res3plus.csv')\n",
    "    elif pred_col in pred_cols_res1to2:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv')\n",
    "\n",
    "    df_import = df_import.dropna(subset=[pred_col, 'TotalPower'])    \n",
    "    df_accu = df_import.replace([np.inf, -np.inf], np.nan).dropna(subset=['TotalPower', pred_col]).copy()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_accu[pred_col],\n",
    "            y=df_accu['TotalPower'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=3, opacity=0.5),\n",
    "            name=pred_col,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "    # add diagonal line y=x\n",
    "    min_val = min(df_accu['TotalPower'].min(), df_accu[pred_col].min()) * 0.95\n",
    "    max_val = max(df_accu['TotalPower'].max(), df_accu[pred_col].max()) * 1.05\n",
    "    fig.add_trace(go.Scatter(x=[min_val, max_val],\n",
    "                                y=[min_val, max_val],\n",
    "                                mode='lines',\n",
    "                                line=dict(color='red', dash='dash'),\n",
    "                                name='Perfect Prediction',\n",
    "                                showlegend=False),\n",
    "                    row=row, col=col)\n",
    "\n",
    "    fig.update_xaxes(title_text=f'PredPwr {df_accu.shape[0]}n', row=row, col=col)\n",
    "    fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "# layout \n",
    "fig.update_layout(\n",
    "    # height=300 * nrows, width=1000,\n",
    "                  title_text=f'Predicted Power vs Total Power ({df_accu.shape[0]} n_df_train, {df_accu.shape[0]} n_df_test)',\n",
    "                  plot_bgcolor='white')\n",
    "for i in range(1, nplots + 1):\n",
    "    row = (i - 1) // ncols + 1\n",
    "    col = (i - 1) % ncols + 1\n",
    "    # fig.update_xaxes(title_text='Predicted Power', row=row, col=col)\n",
    "    # fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "fig.write_html(f'{name_dir_export_path_PY}/reg2_pred_vs_total_power.html')\n",
    "\n",
    "\n",
    "# RMSE plot ------------\n",
    "rmse_dict = {}\n",
    "for pred_col in pred_cols:\n",
    "    \n",
    "    if pred_col in pred_cols_reg:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "    elif pred_col in pred_cols_res3plus:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res3plus.csv')\n",
    "    elif pred_col in pred_cols_res1to2:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv')\n",
    "\n",
    "    df_import = df_import.dropna(subset=[pred_col, 'TotalPower'])    \n",
    "    df_accu = df_import.replace([np.inf, -np.inf], np.nan).dropna(subset=['TotalPower', pred_col]).copy()\n",
    "    \n",
    "    rmse = mean_squared_error(df_accu['TotalPower'], df_accu[pred_col])\n",
    "    rmse_dict[pred_col] = rmse\n",
    "\n",
    "bar_fig = go.Figure()\n",
    "\n",
    "bar_fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(rmse_dict.keys()),\n",
    "        y=list(rmse_dict.values()),\n",
    "        marker=dict(color='cornflowerblue'),\n",
    "        text=[f\"{v:.2f}\" for v in rmse_dict.values()],\n",
    "        textposition='auto'\n",
    "    )\n",
    ")\n",
    "\n",
    "bar_fig.update_layout(\n",
    "    title='RMSE of Model Predictions on Test Set',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='RMSE',\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "# Save bar plot\n",
    "bar_fig.write_html(f'{name_dir_export_path_PY}/reg2_rmse_barplot.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16aa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SUMMARY BAR PLOTS\n",
    "# df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "# cols_to_plot_tupls = [\n",
    "#     ('GAREA',              'float',   30  ), \n",
    "#     ('GBAUJ',              'str',     30  ), \n",
    "#     ('GKLAS',              'str',     30  ), \n",
    "#     ('GSTAT',              'str',     30  ), \n",
    "#     ('GENH1',              'str',     30  ), \n",
    "#     ('GWAERZH1',           'str',     30  ), \n",
    "#     ('FLAECHE_total',     'float',    30  ),\n",
    "#     ('elecpri_Rp_kWh',     'float',   30  ), \n",
    "#     ('TotalPower',         'float',   30  ), \n",
    "#     ('pvtarif_Rp_kWh',     'float',   30  ), \n",
    "#     ('west_max_flaeche',   'float',   30  ), \n",
    "#     ('east_max_flaeche',   'float',   30  ), \n",
    "#     ('south_max_flaeche',  'float',   30  ), \n",
    "# ]\n",
    "\n",
    "# ncols = 3\n",
    "# nplots = len (cols_to_plot_tupls)\n",
    "# nrows = math.ceil(nplots / ncols)\n",
    "# subplot_titles = [col for col, _, _ in cols_to_plot_tupls]\n",
    "# fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=subplot_titles, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "# for i, (col, col_type, col_nbins) in enumerate(cols_to_plot_tupls):\n",
    "#     row = (i // ncols) + 1\n",
    "#     col_pos = (i % ncols) + 1\n",
    "#     # print(f'col: {col}, type: {col_type}, bins: {col_nbins}')\n",
    "\n",
    "#     if col_type == 'float':\n",
    "#         sub_fig = px.histogram(df_test, x=col, histnorm='probability density', nbins=col_nbins).data[0]\n",
    "#         fig.add_trace(sub_fig, row=row, col=col_pos)\n",
    "#     elif col_type == 'str':\n",
    "#         sub_fig = px.bar(df_test, x=col).data[0]\n",
    "#         fig.add_trace(sub_fig, row=row, col=col_pos)\n",
    "    \n",
    "\n",
    "# fig.update_layout(title_text=\"Summary Plots of Test Data\", \n",
    "#                   template=\"plotly_white\",)\n",
    "# fig.write_html(f'{name_dir_export_path_PY}/reg2_df_test_summary_plots.html')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbacbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIAL DEPENDENCIES -- FE21 OLS -- \n",
    "if False: \n",
    "\n",
    "    with open(f'{name_dir_export_path_PY}/reg2_fe_model_coef.json', 'r') as f:\n",
    "        reg2_fe_model_coef = json.load(f)\n",
    "\n",
    "    # call coefficients + build plot\n",
    "    fe21_coef = reg2_fe_model_coef['fe21']['coefficients']\n",
    "    fe21_coef_lin = [fe21_coef[0], fe21_coef[2], fe21_coef[4], fe21_coef[6], fe21_coef[8], ]\n",
    "    fe21_coef_quad = [fe21_coef[1], fe21_coef[3], fe21_coef[5], fe21_coef[7], fe21_coef[9], ]\n",
    "\n",
    "    covariates_fe21 = [\n",
    "        \"elecpri_Rp_kWh\",\n",
    "        \"pvtarif_Rp_kWh\",\n",
    "        \"west_max_flaeche\",\n",
    "        \"south_max_flaeche\",\n",
    "        \"east_max_flaeche\",\n",
    "    ]\n",
    "    ncols = 3\n",
    "    nplots = len (covariates_fe21)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "    fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=covariates_fe21, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "\n",
    "    # addjust fixed effects\n",
    "    agg_methods = {covar: 'mean' for covar in covariates_fe21}\n",
    "    df_plot = df_test.copy()\n",
    "    df_means = df_test.groupby(['BFS_NUMMER', 'year']).agg({**agg_methods, 'TotalPower': 'mean'}).reset_index()\n",
    "    df_plot = df_plot.merge(df_means, on=['BFS_NUMMER', 'year'], suffixes=('', '_mean'))\n",
    "    for covar in covariates_fe21:\n",
    "        df_plot[f'{covar}_fe'] = df_plot[f'{covar}'] - df_plot[f'{covar}_mean']\n",
    "    df_plot['TotalPower'] = df_plot['TotalPower'] - df_plot['TotalPower_mean']\n",
    "\n",
    "\n",
    "    for i, covar in enumerate(covariates_fe21):\n",
    "        x_array = np.linspace(0, round(max(df_test[covar]),0), 200)\n",
    "        y_array = fe21_coef_lin[i] * x_array + fe21_coef_quad[i] * (x_array ** 2) \n",
    "\n",
    "        row = (i // ncols) + 1\n",
    "        col = (i % ncols) + 1\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_array,\n",
    "                y=y_array,\n",
    "                mode='lines',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_plot[f'{covar}'],\n",
    "                y=df_plot['TotalPower'],\n",
    "                mode='markers', \n",
    "                marker=dict(size=2, opacity=0.5),\n",
    "                name=col,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "            )\n",
    "        fig.update_xaxes(title_text= f'{col}', row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "        \n",
    "    for i in range(1, nplots + 1):\n",
    "        row = (i - 1) // ncols + 1\n",
    "        col = (i - 1) % ncols + 1\n",
    "        # fig.update_xaxes(title_text= f'{col}', row=row, col=col)\n",
    "        # fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'FE21 Partial Dependence Plots - {df_train.shape[0]} n_df_train, {df_test.shape[0]} n_df_test / {df_plot.shape[0]} n_df_test_fixedef',  \n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "    fig.write_html(f'{name_dir_export_path_PY}/reg2_fe21_partial_dependence.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIAL DEPENDENCIES -- FE31 OLS -- \n",
    "if False: \n",
    "    df_train_res3plus = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train_res3plus.csv')\n",
    "    df_test_res3plus = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res3plus.csv')\n",
    "\n",
    "    with open(f'{name_dir_export_path_PY}/reg2_fe_model_coef.json', 'r') as f:\n",
    "        reg2_fe_model_coef = json.load(f)\n",
    "\n",
    "    # call coefficients + build plot\n",
    "    fe31_coef = reg2_fe_model_coef['fe31']['coefficients']\n",
    "    fe31_coef_lin = [fe31_coef[0], fe31_coef[2], fe31_coef[4], fe31_coef[5], fe31_coef[6], fe31_coef[7], fe31_coef[8], fe31_coef[9], \n",
    "                     fe31_coef[11], fe31_coef[13],]\n",
    "\n",
    "    fe31_coef_quad = [ fe31_coef[1], fe31_coef[3], 0, 0, 0, 0, 0, 0, fe31_coef[10], fe31_coef[12], fe31_coef[14]]\n",
    "\n",
    "    covariates_fe31 = [\n",
    "\n",
    "        \"elecpri_Rp_kWh\",\n",
    "        \"pvtarif_Rp_kWh\",\n",
    "        \"GBAUJ\", \n",
    "        \"GKLAS\", \n",
    "        \"GSTAT\", \n",
    "        \"GWAERZH1\", \n",
    "        \"GENH1\", \n",
    "        \"west_max_flaeche\",\n",
    "        \"south_max_flaeche\",\n",
    "        \"east_max_flaeche\",\n",
    "    ]\n",
    "    ncols = 3\n",
    "    nplots = len (covariates_fe31)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "    fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=covariates_fe31, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "\n",
    "    # addjust fixed effects\n",
    "    agg_methods = {covar: 'mean' for covar in covariates_fe31}\n",
    "    df_plot = df_test_res3plus.copy()\n",
    "    df_means = df_test_res3plus.groupby(['BFS_NUMMER', 'year']).agg({**agg_methods, 'TotalPower': 'mean'}).reset_index()\n",
    "    df_plot = df_plot.merge(df_means, on=['BFS_NUMMER', 'year'], suffixes=('', '_mean'))\n",
    "    for covar in covariates_fe31:\n",
    "        df_plot[f'{covar}_fe'] = df_plot[f'{covar}'] - df_plot[f'{covar}_mean']\n",
    "    df_plot['TotalPower'] = df_plot['TotalPower'] - df_plot['TotalPower_mean']\n",
    "\n",
    "\n",
    "    for i, covar in enumerate(covariates_fe31):\n",
    "        x_array = np.linspace(0, round(max(df_test_res3plus[covar]),0), 200)\n",
    "        y_array = fe31_coef_lin[i] * x_array + fe31_coef_quad[i] * (x_array ** 2) \n",
    "\n",
    "        row = (i // ncols) + 1\n",
    "        col = (i % ncols) + 1\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_array,\n",
    "                y=y_array,\n",
    "                mode='lines',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_plot[f'{covar}'],\n",
    "                y=df_plot['TotalPower'],\n",
    "                mode='markers', \n",
    "                marker=dict(size=2, opacity=0.5),\n",
    "                name=col,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "    for i in range(1, nplots + 1):\n",
    "        row = (i - 1) // ncols + 1\n",
    "        col = (i - 1) % ncols + 1\n",
    "        fig.update_xaxes(title_text= col, row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'FE21 Partial Dependence Plots - {df_train_res3plus.shape[0]} n_df_train, {df_test_res3plus.shape[0]} n_df_test / {df_plot.shape[0]} n_df_test_fixedef',  \n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "    fig.write_html(f'{name_dir_export_path_PY}/reg2_fe31_partial_dependence.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18887af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIAL DEPENDENCIES -- GAM -- \n",
    "if False:\n",
    "    df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "    features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "                'north_max_flaeche', 'south_max_flaeche',\n",
    "                'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "    ncols = 3\n",
    "    nplots = len(features)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=nrows,\n",
    "        cols=ncols,\n",
    "        subplot_titles=features,\n",
    "    )\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        row = (i // ncols) + 1\n",
    "        col = (i % ncols) + 1\n",
    "\n",
    "        # Generate grid of values for feature i\n",
    "        XX = gam1.generate_X_grid(term=i, n=200)\n",
    "\n",
    "        # Predict partial dependence\n",
    "        pdep = gam1.partial_dependence(term=i, X=XX)\n",
    "\n",
    "        # Scatter raw data for visual context\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_test[feature],\n",
    "                y=df_test['TotalPower'],\n",
    "                mode='markers',\n",
    "                marker=dict(size=2, opacity=0.3),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "\n",
    "        # Add partial dependence line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=XX[:, i],\n",
    "                y=pdep,\n",
    "                mode='lines',\n",
    "                line=dict(color='red'),\n",
    "                name=f'PDP: {feature}',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(title_text=feature, row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Partial Effect', row=row, col=col)\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title_text=f'GAM Partial Dependence Plots ({df_train.shape[0]} train, {df_test.shape[0]} test)',\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    # Save HTML output\n",
    "    fig.write_html(f'{name_dir_export_path_PY}/reg2_gam_partial_dependence.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_optimalpv_rh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
