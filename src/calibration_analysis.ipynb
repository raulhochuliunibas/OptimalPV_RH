{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50e16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os as os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sqlite3\n",
    "import copy\n",
    "import itertools\n",
    "import time \n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union\n",
    "from dataclasses import dataclass, field\n",
    "from typing_extensions import List, Dict, Tuple\n",
    "\n",
    "path = os.getcwd().split('\\\\src')[0]\n",
    "os.chdir(path)\n",
    "from src.calibration_class import Calibration_Settings, Calibration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093c09c",
   "metadata": {},
   "source": [
    "### preprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b69ee2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    preprep_list = [\n",
    "        # Calibration_Settings(), \n",
    "\n",
    "        Calibration_Settings(\n",
    "            name_dir_export='calib_mini_debug',\n",
    "            name_preprep_subsen='bfs1201',\n",
    "            bfs_numbers=[1201,],\n",
    "            n_rows_import= 500,\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False\n",
    "        ), \n",
    "        Calibration_Settings(\n",
    "            name_dir_export='calib_mini_debug',\n",
    "            name_preprep_subsen='bfs1205',\n",
    "            bfs_numbers=[1205,],\n",
    "            n_rows_import= 500,\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False\n",
    "        ), \n",
    "        # Calibration_Settings(\n",
    "        #     name_dir_export='calib_mini_debug',\n",
    "        #     name_preprep_subsen='bfs96',\n",
    "        #     bfs_numbers=[96,],\n",
    "        #     n_rows_import= 500,\n",
    "        #     rerun_import_and_preprp_data_TF = True,\n",
    "        #     export_gwr_ALL_building_gdf_TF = False\n",
    "        # ), \n",
    "        # Calibration_Settings(\n",
    "        #     name_dir_export='calib_mini_debug',\n",
    "        #     name_preprep_subsen='bfs1033',\n",
    "        #     bfs_numbers=[1033,],\n",
    "        #     n_rows_import= 500,\n",
    "        #     rerun_import_and_preprp_data_TF = True,\n",
    "        #     export_gwr_ALL_building_gdf_TF = False\n",
    "        # ), \n",
    "    ]\n",
    "\n",
    "    for i_prep, prep_sett in enumerate(preprep_list):\n",
    "        print('')\n",
    "        # preprep_class = Calibration(prep_sett)\n",
    "        # preprep_class.import_and_preprep_data() if preprep_class.sett.rerun_import_and_preprp_data_TF else None\n",
    "\n",
    "    # preprep_class = Calibration(preprep_list[0])\n",
    "    # preprep_class.concatenate_prerep_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a99b6c",
   "metadata": {},
   "source": [
    "### concat preprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7fc5019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "  START CALIBRATION: calib_mini_debug\n",
      "  > name_preprep_subsen: kt4\n",
      "  > name_calib_subscen: test param settings 1\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Models\\\\OptimalPV_RH\\\\data\\\\calibration\\\\calib_mini_debug\\\\preprep_data/gwr_pq.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m calib_settings \u001b[38;5;129;01min\u001b[39;00m calibration_list:\n\u001b[32m     16\u001b[39m     calib_class = Calibration(calib_settings)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43mcalib_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapproach2_regression_instsize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;28;01mif\u001b[39;00m calib_settings.run_approach2_regression_instsize_TF \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\src\\calibration_class.py:1078\u001b[39m, in \u001b[36mapproach2_regression_instsize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1076\u001b[39m             df_agg_list.append(df)\n\u001b[32m   1077\u001b[39m         df_agg = gpd.GeoDataFrame(pd.concat(df_agg_list, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m), crs=df.crs)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.sett.calib_scen_preprep_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.sett.name_dir_export\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   1079\u001b[39m             f.write(df_agg.to_json())\n\u001b[32m   1081\u001b[39m log_time = \u001b[38;5;28mself\u001b[39m.write_to_logfile(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexported: ./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.sett.name_dir_export\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, log_time, \u001b[38;5;28mself\u001b[39m.sett.concat_time_log_path )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    664\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    665\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\pandas\\io\\parquet.py:267\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    265\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    275\u001b[39m         path_or_handle,\n\u001b[32m    276\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m         **kwargs,\n\u001b[32m    280\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\pandas\\io\\parquet.py:140\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    130\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    132\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    144\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Models\\\\OptimalPV_RH\\\\data\\\\calibration\\\\calib_mini_debug\\\\preprep_data/gwr_pq.parquet'"
     ]
    }
   ],
   "source": [
    "calibration_list = [\n",
    "    Calibration_Settings(\n",
    "        name_dir_export='calib_mini_debug',\n",
    "        name_preprep_subsen='kt4',\n",
    "        kt_numbers  =[4, ],\n",
    "        # bfs_numbers =[\n",
    "            # 1201, 1205, \n",
    "            # 96, 1033,\n",
    "        # ],\n",
    "        n_rows_import= 500,\n",
    "        rerun_import_and_preprp_data_TF = False,\n",
    "        export_gwr_ALL_building_gdf_TF = False\n",
    "    ), \n",
    "]\n",
    "for calib_settings in calibration_list:\n",
    "    calib_class = Calibration(calib_settings)\n",
    "    calib_class.approach2_regression_instsize()     if calib_settings.run_approach2_regression_instsize_TF else None\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_optimalpv_rh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
