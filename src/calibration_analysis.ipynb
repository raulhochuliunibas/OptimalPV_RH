{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d50e16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os as os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from pygam import LinearGAM, s\n",
    "\n",
    "# from shapely.geometry import Point\n",
    "# from shapely.ops import unary_union\n",
    "# from dataclasses import dataclass, field\n",
    "# from typing_extensions import List, Dict, Tuple\n",
    "\n",
    "if 'scicore' in os.getcwd():\n",
    "    path = '/scicore/home/krysiak/hocrau00/ondemand/OptimalPV_RH'\n",
    "else:\n",
    "    path = os.getcwd().split('\\\\src')[0]\n",
    "    %load_ext rpy2.ipython\n",
    "\n",
    "os.chdir(path)\n",
    "from src.calibration_class import Calibration_Settings, Calibration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68f42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dir_export_path_PY = 'c:/Models/OptimalPV_RH/data/calibration/calib_all_CH_bfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "189e0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "name_dir_export_path_R <- \"c:/Models/OptimalPV_RH/data/calibration/calib_all_CH_bfs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093c09c",
   "metadata": {},
   "source": [
    "### preprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b69ee2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    preprep_list = [\n",
    "        # Calibration_Settings(), \n",
    "\n",
    "        Calibration_Settings(\n",
    "            name_dir_export='calib_mini_debug',\n",
    "            name_preprep_subsen='bfs1201',\n",
    "            bfs_numbers=[1201,],\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False\n",
    "        ), \n",
    "        Calibration_Settings(\n",
    "            name_dir_export='calib_mini_debug',\n",
    "            name_preprep_subsen='bfs1205',\n",
    "            bfs_numbers=[1205,],\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False\n",
    "        ), \n",
    "        # Calibration_Settings(\n",
    "        #     name_dir_export='calib_mini_debug',\n",
    "        #     name_preprep_subsen='bfs96',\n",
    "        #     bfs_numbers=[96,],\n",
    "        #     rerun_import_and_preprp_data_TF = True,\n",
    "        #     export_gwr_ALL_building_gdf_TF = False\n",
    "        # ), \n",
    "        # Calibration_Settings(\n",
    "        #     name_dir_export='calib_mini_debug',\n",
    "        #     name_preprep_subsen='bfs1033',\n",
    "        #     bfs_numbers=[1033,],\n",
    "        #     rerun_import_and_preprp_data_TF = True,\n",
    "        #     export_gwr_ALL_building_gdf_TF = False\n",
    "        # ), \n",
    "    ]\n",
    "\n",
    "    for i_prep, prep_sett in enumerate(preprep_list):\n",
    "        print('')\n",
    "    #     preprep_class = Calibration(prep_sett)\n",
    "    #     preprep_class.import_and_preprep_data() if preprep_class.sett.rerun_import_and_preprp_data_TF else None\n",
    "\n",
    "    # preprep_class = Calibration(preprep_list[0])\n",
    "    # preprep_class.concatenate_prerep_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a99b6c",
   "metadata": {},
   "source": [
    "### concat preprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2e5f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "  START CALIBRATION: calib_all_CH_bfs\n",
      "  > name_preprep_subsen: preprep_class_default_sett\n",
      "  > name_calib_subscen: calib_class_default_sett\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calib_main_sett = Calibration_Settings(\n",
    "            name_dir_export='calib_all_CH_bfs',\n",
    "            scicore_concat_data_path = r'/scicore/home/krysiak/hocrau00/OptimalPV_RH/data/calibration/',\n",
    "            kt_numbers=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,], \n",
    "            # name_preprep_subsen=f'bfs{bfs_number}',\n",
    "            # bfs_numbers=[bfs_number,], \n",
    "            n_rows_import= None,\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False)\n",
    "calib_main = Calibration(calib_main_sett)\n",
    "# calib_main.concatenate_prerep_data()\n",
    "# calib_main.estimdf2_regression_instsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e84a8e",
   "metadata": {},
   "source": [
    "## approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524bbe33",
   "metadata": {},
   "source": [
    "### data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ebdb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weed out all inf or NaN values \n",
    "df = pd.read_csv(f'{name_dir_export_path_PY}/reg2_all_CH_bfs_df_approach2.csv')\n",
    "df = df.dropna(subset=['BFS_NUMMER', 'TotalPower', 'elecpri_Rp_kWh', 'pvtarif_Rp_kWh', 'north_max_flaeche', 'south_max_flaeche', 'east_max_flaeche', 'west_max_flaeche'])\n",
    "df.to_csv(f'{name_dir_export_path_PY}/reg2_all_CH_bfs_df_cleaned.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a64b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: <class 'UnicodeDecodeError'> 'utf-8' codec can't decode byte 0xfc in position 27: invalid start byte <traceback object at 0x000001F7052CDB40>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "if (!requireNamespace(\"readr\", quietly = TRUE)) install.packages(\"readr\")\n",
    "if (!requireNamespace(\"dplyr\", quietly = TRUE)) install.packages(\"dplyr\")\n",
    "if (!requireNamespace(\"fixest\", quietly = TRUE)) install.packages(\"fixest\")\n",
    "if (!requireNamespace(\"tibble\", quietly = TRUE)) install.packages(\"tibble\")\n",
    "if (!requireNamespace(\"jsonlite\", quietly = TRUE)) install.packages(\"jsonlite\")\n",
    "if (!requireNamespace(\"tidyr\", quietly = TRUE)) install.packages(\"tidyr\")\n",
    "if (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\n",
    "if (!requireNamespace(\"purr\", quietly = TRUE)) install.packages(\"purr\")\n",
    "if (!requireNamespace(\"tidyverse\", quietly = TRUE)) install.packages(\"tidyverse\")\n",
    "if (!requireNamespace(\"randomForest\", quietly = TRUE)) install.packages(\"randomForest\")\n",
    "\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "library(fixest)\n",
    "library(tibble)\n",
    "library(jsonlite)\n",
    "library(tidyr)\n",
    "library(ggplot2)\n",
    "library(purrr)\n",
    "library(tidyverse)\n",
    "library(randomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62b5e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 94433 Columns: 20\n",
      "-- Column specification --------------------------------------------------------\n",
      "Delimiter: \",\"\n",
      "dbl (20): EGID, year, BFS_NUMMER, xtf_id, n_DF_UID, GAREA, GBAUJ, GKLAS, GST...\n",
      "\n",
      "i Use `spec()` to retrieve the full column specification for this data.\n",
      "i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# train / test split-------------\n",
    "# train_test_split = 0.7\n",
    "\n",
    "# import -------------\n",
    "pq_files = list.files(name_dir_export_path_R, pattern = \".parquet\", full.names = TRUE)\n",
    "\n",
    "df <- tibble(read_csv(paste0(name_dir_export_path_R, \"/reg2_all_CH_bfs_df_cleaned.csv\"), locale = locale(encoding = \"UTF-8\")))\n",
    "\n",
    "df <- df %>% \n",
    "  mutate(\n",
    "    GBAUJ = as_factor(GBAUJ),\n",
    "    GKLAS = as_factor(GKLAS),\n",
    "    GSTAT = as_factor(GSTAT),\n",
    "    GWAERZH1 = as_factor(GWAERZH1),\n",
    "    GENH1 = as_factor(GENH1))\n",
    "\n",
    "idx_heatpump <- df$GWAERZH1 %in% c('7410', '7411')\n",
    "df$GWAERZH1_str <- 'no_heatpump'\n",
    "df$GWAERZH1_str[idx_heatpump] <- 'heatpump'\n",
    "df$GWAERZH1_str <- as_factor(df$GWAERZH1_str)\n",
    "\n",
    "\n",
    "# split training & test data -------------\n",
    "split_train_test <- function(df_func, df_sub_type, split_ratio = 0.7, seed = 42) {\n",
    "  set.seed(seed)\n",
    "  train_indices <- sample(1:nrow(df_func), size = split_ratio * nrow(df_func))\n",
    "  df_train_func <- df_func[train_indices, ]\n",
    "  df_test_func <- df_func[-train_indices, ]\n",
    "  \n",
    "  if (df_sub_type == \"train\"){\n",
    "    df_return = df_train_func\n",
    "  }\n",
    "  else if (df_sub_type == \"test\"){\n",
    "    df_return = df_test_func\n",
    "  }\n",
    "  else {\n",
    "    stop(\"df_sub_type must be either 'train' or 'test'\")\n",
    "  } \n",
    "  return(df_return)\n",
    "}\n",
    "\n",
    "df_train <- split_train_test(df, \"train\" )\n",
    "df_test <-  split_train_test(df, \"test\"  )\n",
    "\n",
    "\n",
    "# filter: only residential buildings -------------\n",
    "idx_GKLAS_res3plus <- df$GKLAS %in% c(\"1110\", \"1121\", \"1122\")\n",
    "df__res3plus <- df %>% filter(idx_GKLAS_res3plus)\n",
    "df_train_res3plus <- split_train_test(df__res3plus, \"train\" )\n",
    "df_test_res3plus <-  split_train_test(df__res3plus, \"test\"  )\n",
    "\n",
    "\n",
    "idx_GKLAS_res1to2 <- df$GKLAS %in% c(\"1110\", \"1121\")\n",
    "df__res1to2 <- df %>% filter(idx_GKLAS_res1to2)\n",
    "df_train_res1to2 <- split_train_test(df__res1to2, \"train\" )\n",
    "df_test_res1to2 <-  split_train_test(df__res1to2, \"test\"  )\n",
    "\n",
    "idx_kwpmax20 <- df$TotalPower < 20\n",
    "df__kwpmax20 <- df %>% filter(idx_kwpmax20 & idx_GKLAS_res1to2)\n",
    "df_train_kwpmax20 <- split_train_test(df__kwpmax20, \"train\" )\n",
    "df_test_kwpmax20 <-  split_train_test(df__kwpmax20, \"test\"  )\n",
    "\n",
    "\n",
    "# export training & test data ------------ยง\n",
    "write_csv(df_train, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_train.csv\"))\n",
    "write_csv(df_test, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test.csv\"))\n",
    "\n",
    "write_csv(df_train_res3plus,  paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_res3plus.csv\"))\n",
    "write_csv(df_test_res3plus,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res3plus.csv\"))\n",
    "write_csv(df_train_res1to2,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_res1to2.csv\"))\n",
    "write_csv(df_test_res1to2,    paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res1to2.csv\" ))\n",
    "write_csv(df_train_kwpmax20,  paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_kwpmax20.csv\"))\n",
    "write_csv(df_test_kwpmax20,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_kwpmax20.csv\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d680b26",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54084fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "# fit regression model\n",
    "fe11 <- feols( TotalPower ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche, data = df_train )\n",
    "fe12 <- feols( TotalPower ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche | year, data = df_train    )\n",
    "\n",
    "fe13 <- feols( TotalPower ~\n",
    "    elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "    west_max_flaeche + south_max_flaeche + east_max_flaeche |\n",
    "    BFS_NUMMER,\n",
    "    data = df_train\n",
    "    )\n",
    "df_test$pred_fe13 <- predict(fe13, newdata = df_test)\n",
    "\n",
    "fe14 <- feols( TotalPower ~\n",
    "    elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "    west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "    BFS_NUMMER + year,\n",
    "    data = df_train\n",
    "    )\n",
    "df_test$pred_fe14 <- predict(fe14, newdata = df_test)\n",
    "\n",
    "fe21 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train\n",
    ")\n",
    "df_test$pred_fe21 <- predict(fe21, newdata = df_test)\n",
    "\n",
    "fe24a <- feols(log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh +west_max_flaeche + south_max_flaeche + east_max_flaeche, data = df_train)\n",
    "fe24b <- feols( log(TotalPower) ~  elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche |  year,  data = df_train )\n",
    "\n",
    "fe24c<- feols(\n",
    "    log(TotalPower) ~ \n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER, \n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe24c <- predict(fe24c, newdata = df_test)\n",
    "\n",
    "fe24d<- feols(\n",
    "    log(TotalPower) ~ \n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe24d <- predict(fe24d, newdata = df_test)\n",
    "\n",
    "fe25a<- feols(log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh +west_max_flaeche + south_max_flaeche + east_max_flaeche,data = df_train)\n",
    "fe25b<- feols( log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche |  year, data = df_train)\n",
    "fe25c<- feols(\n",
    "    log(TotalPower) ~\n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe25c <- predict(fe25c, newdata = df_test)\n",
    "\n",
    "fe25d<- feols(\n",
    "    log(TotalPower) ~\n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe25d <- predict(fe25d, newdata = df_test)\n",
    "\n",
    "fe26a <- feols( log(TotalPower) ~  elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) + pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + west_max_flaeche + I(west_max_flaeche^2) + south_max_flaeche + I(south_max_flaeche^2) + east_max_flaeche + I(east_max_flaeche^2), data = df_train)\n",
    "fe26b <- feols( log(TotalPower) ~  elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) + pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + west_max_flaeche + I(west_max_flaeche^2) + south_max_flaeche + I(south_max_flaeche^2) + east_max_flaeche + I(east_max_flaeche^2) | year, data = df_train )\n",
    "fe26c <- feols(\n",
    "    log(TotalPower) ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe26c <- predict(fe26c, newdata = df_test)\n",
    "\n",
    "fe26d <- feols(\n",
    "    log(TotalPower) ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe26d <- predict(fe26d, newdata = df_test)\n",
    "\n",
    "\n",
    "# only residential buildings of small size\n",
    "fe30 <-  feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train\n",
    ")\n",
    "df_test$pred_fe30 <- predict(fe30, newdata = df_test)\n",
    "\n",
    "fe31 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res3plus\n",
    ")\n",
    "df_test_res3plus$pred_fe31 <- predict(fe31, newdata = df_test_res3plus) \n",
    "\n",
    "fe32 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res1to2\n",
    ")\n",
    "df_test_res1to2$pred_fe32 <- predict(fe32, newdata = df_test_res1to2)\n",
    "\n",
    "fe40 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    FLAECHE_total + I(FLAECHE_total^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res3plus\n",
    ")\n",
    "df_test_res3plus$pred_fe40 <- predict(fe40, newdata = df_test_res3plus)\n",
    "\n",
    "fe41 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    FLAECHE_total + I(FLAECHE_total^2) |  \n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res1to2\n",
    ")\n",
    "df_test_res1to2$pred_fe41 <- predict(fe41, newdata = df_test_res1to2)\n",
    "\n",
    "\n",
    "write_csv(df_test, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test.csv\"))\n",
    "write_csv(df_test_res3plus, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res3plus.csv\"))\n",
    "write_csv(df_test_res1to2, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res1to2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c7b6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "fe_model_list <- list(\n",
    "  fe11 = fe11, fe12 = fe12, fe13 = fe13, fe14 = fe14, \n",
    "  fe21 = fe21, \n",
    "  # fe22 = fe22, fe23 = fe23,\n",
    "  fe24a = fe24a, fe24b = fe24b, fe24c = fe24c, fe24d = fe24d, \n",
    "  fe25a = fe25a, fe25b = fe25b, fe25c = fe25c, fe25d = fe25d,\n",
    "  fe26a = fe26a, fe26b = fe26b, fe26c = fe26c, fe26d = fe26d,\n",
    "  fe30 = fe30, fe31 = fe31,\n",
    "  fe40 = fe40, fe41 = fe41\n",
    ")\n",
    "\n",
    "# Export model info as a named list\n",
    "model_export <- lapply(fe_model_list, function(model) {\n",
    "  list(\n",
    "    comment = paste(deparse(formula(model)), collapse = \" \"),\n",
    "    coefficients = coef(model)\n",
    "  )\n",
    "})\n",
    "\n",
    "# Write JSON with model names as top-level keys\n",
    "write_json(\n",
    "  model_export,\n",
    "  path = file.path(getwd(), \"data/calibration/calib_all_CH_bfs/reg2_fe_model_coef.json\"),\n",
    "  pretty = TRUE,\n",
    "  auto_unbox = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcfc62",
   "metadata": {},
   "source": [
    "### ML random forest regression - full sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e88d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ML_rfr_TF = True\n",
    "rfr_settings = {'comment_settings_RandomForestRegressor()': \n",
    "    \"\"\"\n",
    "        n_estimators:       Defines the number of decision trees in the Random Forest.\n",
    "        random_state=0:     Ensures the randomness in model training is controlled for reproducibility.\n",
    "        oob_score=True:     Enables out-of-bag scoring which evaluates the model's performance using data \n",
    "                            not seen by individual trees during training\n",
    "        max_depth:          The maximum depth of the tree. If None, then nodes are expanded until all \n",
    "                            leaves are pure or until all leaves contain less than min_samples_split \n",
    "                            samples\n",
    "\n",
    "    \"\"\",\n",
    "    'n_estimators':         100 ,    # default: 100   # | 1,       \n",
    "    'min_samples_split':    5   ,    # default: 2     # | 1000,    \n",
    "    'max_depth':            20  ,    # default: None  # | 3,       \n",
    "    'random_state':         None,    # default: None  # | None,    \n",
    "    'n_jobs':               -1       # default: None  # | -1,      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb3837c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_suffix = ''\n",
    "rfr_mod_name = 'rfr1'\n",
    "df_train_rfr = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train{df_suffix}.csv')\n",
    "df_test_rfr  = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a666cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "df_train_rfr = df_train_rfr.drop(columns=['EGID', 'xtf_id', 'n_DF_UID']).copy()\n",
    "cols_dtypes_tupls = {\n",
    "    'year': 'int64',\n",
    "    'BFS_NUMMER': 'category',\n",
    "    'GAREA': 'float64',\n",
    "    'GBAUJ': 'int64',   \n",
    "    'GKLAS': 'category',\n",
    "    'GSTAT': 'category',\n",
    "    'GWAERZH1': 'category',\n",
    "    'GENH1': 'category',\n",
    "    'GWAERZH1_str': 'category',\n",
    "    'InitialPower': 'float64',\n",
    "    'TotalPower': 'float64',\n",
    "    'elecpri_Rp_kWh': 'float64',\n",
    "    'pvtarif_Rp_kWh': 'float64',\n",
    "    'FLAECHE_total': 'float64',\n",
    "    'east_max_flaeche': 'float64',\n",
    "    'west_max_flaeche': 'float64',\n",
    "    'north_max_flaeche': 'float64',\n",
    "    'south_max_flaeche': 'float64',\n",
    "}\n",
    "for col, dtype in cols_dtypes_tupls.items():\n",
    "    df_train_rfr[col] = df_train_rfr[col].astype(dtype)\n",
    "    df_test_rfr[col]  = df_test_rfr[col].astype(dtype)\n",
    "\n",
    "df_train_rfr = df_train_rfr.dropna().copy()\n",
    "df_test_rfr  = df_test_rfr.dropna().copy()\n",
    "\n",
    "X = df_train_rfr.drop(columns=['TotalPower', ])\n",
    "y = df_train_rfr['TotalPower']\n",
    "\n",
    "# encode categorical variables\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_Arry = encoder.fit_transform(X[cat_cols].astype(str))\n",
    "encoded_df = pd.DataFrame(encoded_Arry, columns=encoder.get_feature_names_out(cat_cols))\n",
    "X = pd.concat([X.drop(columns=cat_cols).reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# rf model\n",
    "if run_ML_rfr_TF:\n",
    "    rfr_model = RandomForestRegressor(\n",
    "        n_estimators   = rfr_settings['n_estimators'],\n",
    "        max_depth      = rfr_settings['max_depth'],\n",
    "        random_state   = rfr_settings['random_state'],\n",
    "        n_jobs         = rfr_settings['n_jobs'],\n",
    "    )\n",
    "    # cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(rfr_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    rfr_model.fit(X, y)\n",
    "\n",
    "    # save model\n",
    "    mod_path = f'{name_dir_export_path_PY}/reg2_{rfr_mod_name}_{df_suffix}_model.pkl'\n",
    "    joblib.dump(rfr_model, mod_path)\n",
    "\n",
    "\n",
    "# prediction\n",
    "if run_ML_rfr_TF:\n",
    "    X_test = df_test_rfr.drop(columns=['TotalPower', ])\n",
    "    encoded_test_array = encoder.transform(X_test[cat_cols].astype(str))\n",
    "    encoded_test_df = pd.DataFrame(encoded_test_array, columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "    X_test_final = pd.concat([X_test.drop(columns=cat_cols).reset_index(drop=True), encoded_test_df.reset_index(drop=True)], axis=1)\n",
    "    X_test_final = X_test_final[X.columns]\n",
    "\n",
    "    test_preds = rfr_model.predict(X_test_final)\n",
    "\n",
    "    df_test_rfr[f'pred_{rfr_mod_name}'] = test_preds\n",
    "\n",
    "else: \n",
    "    df_test_rfr[f'pred_{rfr_mod_name}'] = np.zeros(df_test_rfr.shape[0])\n",
    "# import data\n",
    "df_suffix = ''\n",
    "rfr_mod_name = 'rfr1'\n",
    "df_train_rfr = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train{df_suffix}.csv')\n",
    "df_test_rfr  = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv')\n",
    "\n",
    "\n",
    "# transformations\n",
    "df_train_rfr = df_train_rfr.drop(columns=['EGID', 'xtf_id', 'n_DF_UID']).copy()\n",
    "cols_dtypes_tupls = {\n",
    "    'year': 'int64',\n",
    "    'BFS_NUMMER': 'category',\n",
    "    'GAREA': 'float64',\n",
    "    'GBAUJ': 'int64',   \n",
    "    'GKLAS': 'category',\n",
    "    'GSTAT': 'category',\n",
    "    'GWAERZH1': 'category',\n",
    "    'GENH1': 'category',\n",
    "    'GWAERZH1_str': 'category',\n",
    "    'InitialPower': 'float64',\n",
    "    'TotalPower': 'float64',\n",
    "    'elecpri_Rp_kWh': 'float64',\n",
    "    'pvtarif_Rp_kWh': 'float64',\n",
    "    'FLAECHE_total': 'float64',\n",
    "    'east_max_flaeche': 'float64',\n",
    "    'west_max_flaeche': 'float64',\n",
    "    'north_max_flaeche': 'float64',\n",
    "    'south_max_flaeche': 'float64',\n",
    "}\n",
    "for col, dtype in cols_dtypes_tupls.items():\n",
    "    df_train_rfr[col] = df_train_rfr[col].astype(dtype)\n",
    "    df_test_rfr[col]  = df_test_rfr[col].astype(dtype)\n",
    "\n",
    "df_train_rfr = df_train_rfr.dropna().copy()\n",
    "df_test_rfr  = df_test_rfr.dropna().copy()\n",
    "\n",
    "X = df_train_rfr.drop(columns=['TotalPower', ])\n",
    "y = df_train_rfr['TotalPower']\n",
    "\n",
    "# encode categorical variables\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_Arry = encoder.fit_transform(X[cat_cols].astype(str))\n",
    "encoded_df = pd.DataFrame(encoded_Arry, columns=encoder.get_feature_names_out(cat_cols))\n",
    "X = pd.concat([X.drop(columns=cat_cols).reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# rf model\n",
    "if run_ML_rfr_TF:\n",
    "    rfr_model = RandomForestRegressor(\n",
    "        n_estimators   = rfr_settings['n_estimators'],\n",
    "        max_depth      = rfr_settings['max_depth'],\n",
    "        random_state   = rfr_settings['random_state'],\n",
    "        n_jobs         = rfr_settings['n_jobs'],\n",
    "    )\n",
    "    # cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(rfr_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    rfr_model.fit(X, y)\n",
    "\n",
    "    # save model\n",
    "    mod_path = f'{name_dir_export_path_PY}/reg2_{rfr_mod_name}_{df_suffix}_model.pkl'\n",
    "    joblib.dump(rfr_model, mod_path)\n",
    "\n",
    "\n",
    "# prediction\n",
    "if run_ML_rfr_TF:\n",
    "    X_test = df_test_rfr.drop(columns=['TotalPower', ])\n",
    "    encoded_test_array = encoder.transform(X_test[cat_cols].astype(str))\n",
    "    encoded_test_df = pd.DataFrame(encoded_test_array, columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "    X_test_final = pd.concat([X_test.drop(columns=cat_cols).reset_index(drop=True), encoded_test_df.reset_index(drop=True)], axis=1)\n",
    "    X_test_final = X_test_final[X.columns]\n",
    "\n",
    "    test_preds = rfr_model.predict(X_test_final)\n",
    "\n",
    "    df_test_rfr[f'pred_{rfr_mod_name}'] = test_preds\n",
    "\n",
    "else: \n",
    "    df_test_rfr[f'pred_{rfr_mod_name}'] = np.zeros(df_test_rfr.shape[0])\n",
    "\n",
    "df_test_rfr.to_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv', index=False)\n",
    "del df_train_rfr, df_test_rfr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac61c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# cross validation\u001b[39;00m\n\u001b[32m     51\u001b[39m kf = KFold(n_splits=\u001b[32m10\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m cv_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfr_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneg_mean_absolute_error\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m rfr_model.fit(X, y)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# save model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Models\\OptimalPV_RH\\.venv_optimalpv_rh\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# # OLD VERSION\n",
    "\n",
    "\n",
    "# # transformations\n",
    "# df_train_rfr = df_train_rfr.drop(columns=['EGID', 'xtf_id', 'n_DF_UID']).copy()\n",
    "# cols_dtypes_tupls = {\n",
    "#     'year': 'int64',\n",
    "#     'BFS_NUMMER': 'category',\n",
    "#     'GAREA': 'float64',\n",
    "#     'GBAUJ': 'int64',   \n",
    "#     'GKLAS': 'category',\n",
    "#     'GSTAT': 'category',\n",
    "#     'GWAERZH1': 'category',\n",
    "#     'GENH1': 'category',\n",
    "#     'GWAERZH1_str': 'category',\n",
    "#     'InitialPower': 'float64',\n",
    "#     'TotalPower': 'float64',\n",
    "#     'elecpri_Rp_kWh': 'float64',\n",
    "#     'pvtarif_Rp_kWh': 'float64',\n",
    "#     'FLAECHE_total': 'float64',\n",
    "#     'east_max_flaeche': 'float64',\n",
    "#     'west_max_flaeche': 'float64',\n",
    "#     'north_max_flaeche': 'float64',\n",
    "#     'south_max_flaeche': 'float64',\n",
    "# }\n",
    "# for col, dtype in cols_dtypes_tupls.items():\n",
    "#     df_train_rfr[col] = df_train_rfr[col].astype(dtype)\n",
    "#     df_test_rfr[col]  = df_test_rfr[col].astype(dtype)\n",
    "\n",
    "# df_train_rfr = df_train_rfr.dropna().copy()\n",
    "# df_test_rfr  = df_test_rfr.dropna().copy()\n",
    "\n",
    "# X = df_train_rfr.drop(columns=['TotalPower', ])\n",
    "# y = df_train_rfr['TotalPower']\n",
    "\n",
    "# # encode categorical variables\n",
    "# cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "# cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "# encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# encoded_Arry = encoder.fit_transform(X[cat_cols].astype(str))\n",
    "# encoded_df = pd.DataFrame(encoded_Arry, columns=encoder.get_feature_names_out(cat_cols))\n",
    "# X = pd.concat([X.drop(columns=cat_cols).reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# # rf model\n",
    "# if run_ML_rfr_TF:\n",
    "#     rfr_model = RandomForestRegressor(\n",
    "#         n_estimators   = rfr_settings['n_estimators'],\n",
    "#         max_depth      = rfr_settings['max_depth'],\n",
    "#         random_state   = rfr_settings['random_state'],\n",
    "#         n_jobs         = rfr_settings['n_jobs'],\n",
    "#     )\n",
    "#     # cross validation\n",
    "#     kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     cv_scores = cross_val_score(rfr_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "#     rfr_model.fit(X, y)\n",
    "\n",
    "#     # save model\n",
    "#     mod_path = f'{name_dir_export_path_PY}/reg2_{rfr_mod_name}_{df_suffix}_model.pkl'\n",
    "#     joblib.dump(rfr_model, mod_path)\n",
    "\n",
    "\n",
    "# # prediction\n",
    "# if run_ML_rfr_TF:\n",
    "#     X_test = df_test_rfr.drop(columns=['TotalPower', ])\n",
    "#     encoded_test_array = encoder.transform(X_test[cat_cols].astype(str))\n",
    "#     encoded_test_df = pd.DataFrame(encoded_test_array, columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "#     X_test_final = pd.concat([X_test.drop(columns=cat_cols).reset_index(drop=True), encoded_test_df.reset_index(drop=True)], axis=1)\n",
    "#     X_test_final = X_test_final[X.columns]\n",
    "\n",
    "#     test_preds = rfr_model.predict(X_test_final)\n",
    "\n",
    "#     df_test_rfr[f'pred_{rfr_mod_name}'] = test_preds\n",
    "\n",
    "# else: \n",
    "#     df_test_rfr[f'pred_{rfr_mod_name}'] = np.zeros(df_test_rfr.shape[0])\n",
    "\n",
    "# df_test_rfr.to_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv', index=False)\n",
    "# del df_train_rfr, df_test_rfr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb852d00",
   "metadata": {},
   "source": [
    "### ML random forest regression - reduced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_suffix = '_kwpmax20'\n",
    "rfr_mod_name = 'rfr2'\n",
    "df_train_rfr = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train{df_suffix}.csv')\n",
    "df_test_rfr  = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc85c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_suffix = ''\n",
    "rfr_mod_name = 'rfr1'\n",
    "df_train_rfr = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train{df_suffix}.csv')\n",
    "df_test_rfr  = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv')\n",
    "\n",
    "\n",
    "# transformations\n",
    "df_train_rfr = df_train_rfr.drop(columns=['EGID', 'xtf_id', 'n_DF_UID']).copy()\n",
    "cols_dtypes_tupls = {\n",
    "    'year': 'int64',\n",
    "    'BFS_NUMMER': 'category',\n",
    "    'GAREA': 'float64',\n",
    "    'GBAUJ': 'int64',   \n",
    "    'GKLAS': 'category',\n",
    "    'GSTAT': 'category',\n",
    "    'GWAERZH1': 'category',\n",
    "    'GENH1': 'category',\n",
    "    'GWAERZH1_str': 'category',\n",
    "    'InitialPower': 'float64',\n",
    "    'TotalPower': 'float64',\n",
    "    'elecpri_Rp_kWh': 'float64',\n",
    "    'pvtarif_Rp_kWh': 'float64',\n",
    "    'FLAECHE_total': 'float64',\n",
    "    'east_max_flaeche': 'float64',\n",
    "    'west_max_flaeche': 'float64',\n",
    "    'north_max_flaeche': 'float64',\n",
    "    'south_max_flaeche': 'float64',\n",
    "}\n",
    "for col, dtype in cols_dtypes_tupls.items():\n",
    "    df_train_rfr[col] = df_train_rfr[col].astype(dtype)\n",
    "    df_test_rfr[col]  = df_test_rfr[col].astype(dtype)\n",
    "\n",
    "df_train_rfr = df_train_rfr.dropna().copy()\n",
    "df_test_rfr  = df_test_rfr.dropna().copy()\n",
    "\n",
    "X = df_train_rfr.drop(columns=['TotalPower', ])\n",
    "y = df_train_rfr['TotalPower']\n",
    "\n",
    "# encode categorical variables\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_Arry = encoder.fit_transform(X[cat_cols].astype(str))\n",
    "encoded_df = pd.DataFrame(encoded_Arry, columns=encoder.get_feature_names_out(cat_cols))\n",
    "X = pd.concat([X.drop(columns=cat_cols).reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# rf model\n",
    "if run_ML_rfr_TF:\n",
    "    rfr_model = RandomForestRegressor(\n",
    "        n_estimators   = rfr_settings['n_estimators'],\n",
    "        max_depth      = rfr_settings['max_depth'],\n",
    "        random_state   = rfr_settings['random_state'],\n",
    "        n_jobs         = rfr_settings['n_jobs'],\n",
    "    )\n",
    "    # cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(rfr_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    rfr_model.fit(X, y)\n",
    "\n",
    "    # save model\n",
    "    mod_path = f'{name_dir_export_path_PY}/reg2_{rfr_mod_name}_{df_suffix}_model.pkl'\n",
    "    joblib.dump(rfr_model, mod_path)\n",
    "\n",
    "\n",
    "# prediction\n",
    "if run_ML_rfr_TF:\n",
    "    X_test = df_test_rfr.drop(columns=['TotalPower', ])\n",
    "    encoded_test_array = encoder.transform(X_test[cat_cols].astype(str))\n",
    "    encoded_test_df = pd.DataFrame(encoded_test_array, columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "    X_test_final = pd.concat([X_test.drop(columns=cat_cols).reset_index(drop=True), encoded_test_df.reset_index(drop=True)], axis=1)\n",
    "    X_test_final = X_test_final[X.columns]\n",
    "\n",
    "    test_preds = rfr_model.predict(X_test_final)\n",
    "\n",
    "    df_test_rfr[f'pred_{rfr_mod_name}'] = test_preds\n",
    "\n",
    "else: \n",
    "    df_test_rfr[f'pred_{rfr_mod_name}'] = np.zeros(df_test_rfr.shape[0])\n",
    "# import data\n",
    "df_suffix = ''\n",
    "rfr_mod_name = 'rfr1'\n",
    "df_train_rfr = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train{df_suffix}.csv')\n",
    "df_test_rfr  = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv')\n",
    "\n",
    "\n",
    "# transformations\n",
    "df_train_rfr = df_train_rfr.drop(columns=['EGID', 'xtf_id', 'n_DF_UID']).copy()\n",
    "cols_dtypes_tupls = {\n",
    "    'year': 'int64',\n",
    "    'BFS_NUMMER': 'category',\n",
    "    'GAREA': 'float64',\n",
    "    'GBAUJ': 'int64',   \n",
    "    'GKLAS': 'category',\n",
    "    'GSTAT': 'category',\n",
    "    'GWAERZH1': 'category',\n",
    "    'GENH1': 'category',\n",
    "    'GWAERZH1_str': 'category',\n",
    "    'InitialPower': 'float64',\n",
    "    'TotalPower': 'float64',\n",
    "    'elecpri_Rp_kWh': 'float64',\n",
    "    'pvtarif_Rp_kWh': 'float64',\n",
    "    'FLAECHE_total': 'float64',\n",
    "    'east_max_flaeche': 'float64',\n",
    "    'west_max_flaeche': 'float64',\n",
    "    'north_max_flaeche': 'float64',\n",
    "    'south_max_flaeche': 'float64',\n",
    "}\n",
    "for col, dtype in cols_dtypes_tupls.items():\n",
    "    df_train_rfr[col] = df_train_rfr[col].astype(dtype)\n",
    "    df_test_rfr[col]  = df_test_rfr[col].astype(dtype)\n",
    "\n",
    "df_train_rfr = df_train_rfr.dropna().copy()\n",
    "df_test_rfr  = df_test_rfr.dropna().copy()\n",
    "\n",
    "X = df_train_rfr.drop(columns=['TotalPower', ])\n",
    "y = df_train_rfr['TotalPower']\n",
    "\n",
    "# encode categorical variables\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_Arry = encoder.fit_transform(X[cat_cols].astype(str))\n",
    "encoded_df = pd.DataFrame(encoded_Arry, columns=encoder.get_feature_names_out(cat_cols))\n",
    "X = pd.concat([X.drop(columns=cat_cols).reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# rf model\n",
    "if run_ML_rfr_TF:\n",
    "    rfr_model = RandomForestRegressor(\n",
    "        n_estimators   = rfr_settings['n_estimators'],\n",
    "        max_depth      = rfr_settings['max_depth'],\n",
    "        random_state   = rfr_settings['random_state'],\n",
    "        n_jobs         = rfr_settings['n_jobs'],\n",
    "    )\n",
    "    # cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(rfr_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    rfr_model.fit(X, y)\n",
    "\n",
    "    # save model\n",
    "    mod_path = f'{name_dir_export_path_PY}/reg2_{rfr_mod_name}_{df_suffix}_model.pkl'\n",
    "    joblib.dump(rfr_model, mod_path)\n",
    "\n",
    "\n",
    "# prediction\n",
    "if run_ML_rfr_TF:\n",
    "    X_test = df_test_rfr.drop(columns=['TotalPower', ])\n",
    "    encoded_test_array = encoder.transform(X_test[cat_cols].astype(str))\n",
    "    encoded_test_df = pd.DataFrame(encoded_test_array, columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "    X_test_final = pd.concat([X_test.drop(columns=cat_cols).reset_index(drop=True), encoded_test_df.reset_index(drop=True)], axis=1)\n",
    "    X_test_final = X_test_final[X.columns]\n",
    "\n",
    "    test_preds = rfr_model.predict(X_test_final)\n",
    "\n",
    "    df_test_rfr[f'pred_{rfr_mod_name}'] = test_preds\n",
    "\n",
    "else: \n",
    "    df_test_rfr[f'pred_{rfr_mod_name}'] = np.zeros(df_test_rfr.shape[0])\n",
    "\n",
    "df_test_rfr.to_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv', index=False)\n",
    "del df_train_rfr, df_test_rfr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d8ee5",
   "metadata": {},
   "source": [
    "### GAM - Generalized Additive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90521dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train.csv')\n",
    "df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "            'north_max_flaeche', 'south_max_flaeche',\n",
    "            'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "x_train = df_train[features].values\n",
    "y_train = df_train['TotalPower'].values\n",
    "\n",
    "x_test = df_test[features].values\n",
    "y_test = df_test['TotalPower'].values\n",
    "\n",
    "gam1 = LinearGAM(\n",
    "    s(0) + s(1) + s(2) + s(3) + s(4) + s(5)\n",
    ").fit(x_train, y_train)\n",
    "y_pred_gam1 = gam1.predict(x_train)\n",
    "df_test['pred_gam1'] = gam1.predict(x_test)\n",
    "\n",
    "# export coefs and df_test\n",
    "model_formula = \"TotalPower ~ s(elecpri_Rp_kWh) + s(pvtarif_Rp_kWh) + s(north_max_flaeche) + s(south_max_flaeche) + s(east_max_flaeche) + s(west_max_flaeche)\"\n",
    "coefficients = gam1.coef_.tolist()\n",
    "lambdas = list(gam1.lam)\n",
    "terms = [str(gam1.terms[i]) for i in range(len(gam1.terms))]\n",
    "reg2_gam_model_coef = {\n",
    "    \"comment\": model_formula,\n",
    "    \"coefficients\": coefficients,\n",
    "    \"lambdas\": lambdas,\n",
    "    \"terms\": terms\n",
    "}\n",
    "with open(f'{name_dir_export_path_PY}/reg2_gam_model_coef.json', 'w') as f:\n",
    "    json.dump(reg2_gam_model_coef, f, indent=4)\n",
    "\n",
    "df_test.to_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41821458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_res1to2 =  pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train_res1to2.csv')\n",
    "df_test_res1to2 =   pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv' )\n",
    "\n",
    "features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "            'north_max_flaeche', 'south_max_flaeche',\n",
    "            'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "x_train = df_train_res1to2[features].values\n",
    "y_train = df_train_res1to2['TotalPower'].values\n",
    "\n",
    "x_test = df_test_res1to2[features].values\n",
    "y_test = df_test_res1to2['TotalPower'].values\n",
    "\n",
    "gam2 = LinearGAM(\n",
    "    s(0) + s(1) + s(2) + s(3) + s(4) + s(5)\n",
    ").fit(x_train, y_train)\n",
    "y_pred_gam2 = gam2.predict(x_train)\n",
    "df_test_res1to2['pred_gam2'] = gam2.predict(x_test)\n",
    "\n",
    "# export coefs and df_test\n",
    "model_formula = \"TotalPower ~ s(elecpri_Rp_kWh) + s(pvtarif_Rp_kWh) + s(north_max_flaeche) + s(south_max_flaeche) + s(east_max_flaeche) + s(west_max_flaeche)\"\n",
    "coefficients = gam2.coef_.tolist()\n",
    "lambdas = list(gam2.lam)\n",
    "terms = [str(gam2.terms[i]) for i in range(len(gam2.terms))]\n",
    "reg2_gam_model_coef = {\n",
    "    \"comment\": model_formula,\n",
    "    \"coefficients\": coefficients,\n",
    "    \"lambdas\": lambdas,\n",
    "    \"terms\": terms\n",
    "}\n",
    "with open(f'{name_dir_export_path_PY}/reg2_gam_model_coef.json', 'w') as f:\n",
    "    json.dump(reg2_gam_model_coef, f, indent=4)\n",
    "\n",
    "df_test_res1to2.to_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fd345",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16aa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY BAR PLOTS\n",
    "df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "cols_to_plot_tupls = [\n",
    "    ('GAREA',              'float',   30  ), \n",
    "    ('GBAUJ',              'str',     30  ), \n",
    "    ('GKLAS',              'str',     30  ), \n",
    "    ('GSTAT',              'str',     30  ), \n",
    "    ('GENH1',              'str',     30  ), \n",
    "    ('GWAERZH1',           'str',     30  ), \n",
    "    ('FLAECHE_total',     'float',    30  ),\n",
    "    ('elecpri_Rp_kWh',     'float',   30  ), \n",
    "    ('TotalPower',         'float',   30  ), \n",
    "    ('pvtarif_Rp_kWh',     'float',   30  ), \n",
    "    ('west_max_flaeche',   'float',   30  ), \n",
    "    ('east_max_flaeche',   'float',   30  ), \n",
    "    ('south_max_flaeche',  'float',   30  ), \n",
    "]\n",
    "\n",
    "ncols = 3\n",
    "nplots = len (cols_to_plot_tupls)\n",
    "nrows = math.ceil(nplots / ncols)\n",
    "subplot_titles = [col for col, _, _ in cols_to_plot_tupls]\n",
    "fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=subplot_titles, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "for i, (col, col_type, col_nbins) in enumerate(cols_to_plot_tupls):\n",
    "    row = (i // ncols) + 1\n",
    "    col_pos = (i % ncols) + 1\n",
    "    # print(f'col: {col}, type: {col_type}, bins: {col_nbins}')\n",
    "\n",
    "    if col_type == 'float':\n",
    "        sub_fig = px.histogram(df_test, x=col, histnorm='probability density', nbins=col_nbins).data[0]\n",
    "        fig.add_trace(sub_fig, row=row, col=col_pos)\n",
    "    elif col_type == 'str':\n",
    "        sub_fig = px.bar(df_test, x=col).data[0]\n",
    "        fig.add_trace(sub_fig, row=row, col=col_pos)\n",
    "    \n",
    "\n",
    "fig.update_layout(title_text=\"Summary Plots of Test Data\", \n",
    "                  template=\"plotly_white\",)\n",
    "fig.write_html(f'{name_dir_export_path_PY}/reg2_df_test_summary_plots.html')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d144886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION ACCURACY PLOTS\n",
    "\n",
    "    # 'pred_fe11', 'pred_fe12', \n",
    "    #  'pred_fe22', 'pred_fe23', \n",
    "    # 'pred_fe24a', 'pred_fe24b', \n",
    "    # 'pred_fe25a', 'pred_fe25b', \n",
    "    # 'pred_fe26a', 'pred_fe26b', \n",
    "pred_cols_reg = [\n",
    "    # 'pred_fe13', \n",
    "    # 'pred_fe14', \n",
    "    'pred_fe21',\n",
    "    # 'pred_fe24c','pred_fe24d', \n",
    "    # 'pred_fe25c', 'pred_fe25d',\n",
    "    # 'pred_fe26c', 'pred_fe26d',\n",
    "    # 'pred_gam1',\n",
    "    'pred_fe30',\n",
    "    'pred_rfr1',\n",
    "]\n",
    "pred_cols_res3plus = [\n",
    "    'pred_fe31', 'pred_fe40'\n",
    "    ]\n",
    "pred_cols_res1to2 = [\n",
    "    'pred_fe32', 'pred_fe41',\n",
    "    # 'pred_gam2',\n",
    "    'pred_rfr2',\n",
    "    ]  \n",
    "pred_cols = pred_cols_reg + pred_cols_res3plus + pred_cols_res1to2\n",
    "\n",
    "\n",
    "# accuracy plot ------------\n",
    "\n",
    "ncols = 4\n",
    "nplots = len (pred_cols)\n",
    "nrows = math.ceil(nplots / ncols)\n",
    "fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=pred_cols, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "for i, pred_col in enumerate(pred_cols):\n",
    "    row = (i // ncols) + 1\n",
    "    col = (i % ncols) + 1\n",
    "\n",
    "    if pred_col in pred_cols_reg:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "    elif pred_col in pred_cols_res3plus:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res3plus.csv')\n",
    "    elif pred_col in pred_cols_res1to2:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv')\n",
    "\n",
    "    df_import = df_import.dropna(subset=[pred_col, 'TotalPower'])    \n",
    "    df_accu = df_import.replace([np.inf, -np.inf], np.nan).dropna(subset=['TotalPower', pred_col]).copy()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_accu[pred_col],\n",
    "            y=df_accu['TotalPower'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=3, opacity=0.5),\n",
    "            name=pred_col,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "    # add diagonal line y=x\n",
    "    min_val = min(df_accu['TotalPower'].min(), df_accu[pred_col].min()) * 0.95\n",
    "    max_val = max(df_accu['TotalPower'].max(), df_accu[pred_col].max()) * 1.05\n",
    "    fig.add_trace(go.Scatter(x=[min_val, max_val],\n",
    "                                y=[min_val, max_val],\n",
    "                                mode='lines',\n",
    "                                line=dict(color='red', dash='dash'),\n",
    "                                name='Perfect Prediction',\n",
    "                                showlegend=False),\n",
    "                    row=row, col=col)\n",
    "\n",
    "    fig.update_xaxes(title_text=f'PredPwr {df_accu.shape[0]}n', row=row, col=col)\n",
    "    fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "# layout \n",
    "fig.update_layout(\n",
    "    # height=300 * nrows, width=1000,\n",
    "                  title_text=f'Predicted Power vs Total Power ({df_accu.shape[0]} n_df_train, {df_accu.shape[0]} n_df_test)',\n",
    "                  plot_bgcolor='white')\n",
    "for i in range(1, nplots + 1):\n",
    "    row = (i - 1) // ncols + 1\n",
    "    col = (i - 1) % ncols + 1\n",
    "    # fig.update_xaxes(title_text='Predicted Power', row=row, col=col)\n",
    "    # fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "# fig.show()\n",
    "fig.write_html(f'{name_dir_export_path_PY}/reg2_pred_vs_total_power.html')\n",
    "# fig.write_image(f'{name_dir_export_path_PY}/reg2_pred_vs_total_power.png', scale=2)\n",
    "\n",
    "\n",
    "# RMSE plot ------------\n",
    "rmse_dict = {}\n",
    "for pred_col in pred_cols:\n",
    "    \n",
    "    if pred_col in pred_cols_reg:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "    elif pred_col in pred_cols_res3plus:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res3plus.csv')\n",
    "    elif pred_col in pred_cols_res1to2:\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv')\n",
    "\n",
    "    df_import = df_import.dropna(subset=[pred_col, 'TotalPower'])    \n",
    "    df_accu = df_import.replace([np.inf, -np.inf], np.nan).dropna(subset=['TotalPower', pred_col]).copy()\n",
    "    \n",
    "    rmse = mean_squared_error(df_accu['TotalPower'], df_accu[pred_col])\n",
    "    rmse_dict[pred_col] = rmse\n",
    "\n",
    "bar_fig = go.Figure()\n",
    "\n",
    "bar_fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(rmse_dict.keys()),\n",
    "        y=list(rmse_dict.values()),\n",
    "        marker=dict(color='cornflowerblue'),\n",
    "        text=[f\"{v:.2f}\" for v in rmse_dict.values()],\n",
    "        textposition='auto'\n",
    "    )\n",
    ")\n",
    "\n",
    "bar_fig.update_layout(\n",
    "    title='RMSE of Model Predictions on Test Set',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='RMSE',\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "# Save bar plot\n",
    "bar_fig.write_html(f'{name_dir_export_path_PY}/reg2_rmse_barplot.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbacbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIAL DEPENDENCIES -- FE21 OLS -- \n",
    "with open(f'{name_dir_export_path_PY}/reg2_fe_model_coef.json', 'r') as f:\n",
    "    reg2_fe_model_coef = json.load(f)\n",
    "\n",
    "# call coefficients + build plot\n",
    "fe21_coef = reg2_fe_model_coef['fe21']['coefficients']\n",
    "fe21_coef_lin = [fe21_coef[0], fe21_coef[2], fe21_coef[4], fe21_coef[6], fe21_coef[8], ]\n",
    "fe21_coef_quad = [fe21_coef[1], fe21_coef[3], fe21_coef[5], fe21_coef[7], fe21_coef[9], ]\n",
    "\n",
    "covariates_fe21 = [\n",
    "    \"elecpri_Rp_kWh\",\n",
    "    \"pvtarif_Rp_kWh\",\n",
    "    \"west_max_flaeche\",\n",
    "    \"south_max_flaeche\",\n",
    "    \"east_max_flaeche\",\n",
    "]\n",
    "ncols = 3\n",
    "nplots = len (covariates_fe21)\n",
    "nrows = math.ceil(nplots / ncols)\n",
    "fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=covariates_fe21, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "\n",
    "# addjust fixed effects\n",
    "agg_methods = {covar: 'mean' for covar in covariates_fe21}\n",
    "df_plot = df_test.copy()\n",
    "df_means = df_test.groupby(['BFS_NUMMER', 'year']).agg({**agg_methods, 'TotalPower': 'mean'}).reset_index()\n",
    "df_plot = df_plot.merge(df_means, on=['BFS_NUMMER', 'year'], suffixes=('', '_mean'))\n",
    "for covar in covariates_fe21:\n",
    "    df_plot[f'{covar}_fe'] = df_plot[f'{covar}'] - df_plot[f'{covar}_mean']\n",
    "df_plot['TotalPower'] = df_plot['TotalPower'] - df_plot['TotalPower_mean']\n",
    "\n",
    "\n",
    "for i, covar in enumerate(covariates_fe21):\n",
    "    x_array = np.linspace(0, round(max(df_test[covar]),0), 200)\n",
    "    y_array = fe21_coef_lin[i] * x_array + fe21_coef_quad[i] * (x_array ** 2) \n",
    "\n",
    "    row = (i // ncols) + 1\n",
    "    col = (i % ncols) + 1\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_array,\n",
    "            y=y_array,\n",
    "            mode='lines',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_plot[f'{covar}'],\n",
    "            y=df_plot['TotalPower'],\n",
    "            mode='markers', \n",
    "            marker=dict(size=2, opacity=0.5),\n",
    "            name=col,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "        )\n",
    "    fig.update_xaxes(title_text= f'{col}', row=row, col=col)\n",
    "    fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "    \n",
    "for i in range(1, nplots + 1):\n",
    "    row = (i - 1) // ncols + 1\n",
    "    col = (i - 1) % ncols + 1\n",
    "    # fig.update_xaxes(title_text= f'{col}', row=row, col=col)\n",
    "    # fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=f'FE21 Partial Dependence Plots - {df_train.shape[0]} n_df_train, {df_test.shape[0]} n_df_test / {df_plot.shape[0]} n_df_test_fixedef',  \n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "fig.write_html(f'{name_dir_export_path_PY}/reg2_fe21_partial_dependence.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIAL DEPENDENCIES -- FE31 OLS -- \n",
    "df_train_res3plus = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train_res3plus.csv')\n",
    "df_test_res3plus = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res3plus.csv')\n",
    "\n",
    "with open(f'{name_dir_export_path_PY}/reg2_fe_model_coef.json', 'r') as f:\n",
    "    reg2_fe_model_coef = json.load(f)\n",
    "\n",
    "# call coefficients + build plot\n",
    "fe31_coef = reg2_fe_model_coef['fe31']['coefficients']\n",
    "fe31_coef_lin = [fe31_coef[0], fe31_coef[2], fe31_coef[4], fe31_coef[5], fe31_coef[6], fe31_coef[7], fe31_coef[8], fe31_coef[9], \n",
    "                 fe31_coef[11], fe31_coef[13],]\n",
    "\n",
    "fe31_coef_quad = [ fe31_coef[1], fe31_coef[3], 0, 0, 0, 0, 0, 0, fe31_coef[10], fe31_coef[12], fe31_coef[14]]\n",
    "\n",
    "covariates_fe31 = [\n",
    "\n",
    "    \"elecpri_Rp_kWh\",\n",
    "    \"pvtarif_Rp_kWh\",\n",
    "    \"GBAUJ\", \n",
    "    \"GKLAS\", \n",
    "    \"GSTAT\", \n",
    "    \"GWAERZH1\", \n",
    "    \"GENH1\", \n",
    "    \"west_max_flaeche\",\n",
    "    \"south_max_flaeche\",\n",
    "    \"east_max_flaeche\",\n",
    "]\n",
    "ncols = 3\n",
    "nplots = len (covariates_fe31)\n",
    "nrows = math.ceil(nplots / ncols)\n",
    "fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=covariates_fe31, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "\n",
    "# addjust fixed effects\n",
    "agg_methods = {covar: 'mean' for covar in covariates_fe31}\n",
    "df_plot = df_test_res3plus.copy()\n",
    "df_means = df_test_res3plus.groupby(['BFS_NUMMER', 'year']).agg({**agg_methods, 'TotalPower': 'mean'}).reset_index()\n",
    "df_plot = df_plot.merge(df_means, on=['BFS_NUMMER', 'year'], suffixes=('', '_mean'))\n",
    "for covar in covariates_fe31:\n",
    "    df_plot[f'{covar}_fe'] = df_plot[f'{covar}'] - df_plot[f'{covar}_mean']\n",
    "df_plot['TotalPower'] = df_plot['TotalPower'] - df_plot['TotalPower_mean']\n",
    "\n",
    "\n",
    "for i, covar in enumerate(covariates_fe31):\n",
    "    x_array = np.linspace(0, round(max(df_test_res3plus[covar]),0), 200)\n",
    "    y_array = fe31_coef_lin[i] * x_array + fe31_coef_quad[i] * (x_array ** 2) \n",
    "\n",
    "    row = (i // ncols) + 1\n",
    "    col = (i % ncols) + 1\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_array,\n",
    "            y=y_array,\n",
    "            mode='lines',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_plot[f'{covar}'],\n",
    "            y=df_plot['TotalPower'],\n",
    "            mode='markers', \n",
    "            marker=dict(size=2, opacity=0.5),\n",
    "            name=col,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "for i in range(1, nplots + 1):\n",
    "    row = (i - 1) // ncols + 1\n",
    "    col = (i - 1) % ncols + 1\n",
    "    fig.update_xaxes(title_text= col, row=row, col=col)\n",
    "    fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=f'FE21 Partial Dependence Plots - {df_train_res3plus.shape[0]} n_df_train, {df_test_res3plus.shape[0]} n_df_test / {df_plot.shape[0]} n_df_test_fixedef',  \n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "fig.write_html(f'{name_dir_export_path_PY}/reg2_fe31_partial_dependence.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18887af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # PARTIAL DEPENDENCIES -- GAM -- \n",
    "    df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "    features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "                'north_max_flaeche', 'south_max_flaeche',\n",
    "                'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "    ncols = 3\n",
    "    nplots = len(features)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=nrows,\n",
    "        cols=ncols,\n",
    "        subplot_titles=features,\n",
    "    )\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        row = (i // ncols) + 1\n",
    "        col = (i % ncols) + 1\n",
    "\n",
    "        # Generate grid of values for feature i\n",
    "        XX = gam1.generate_X_grid(term=i, n=200)\n",
    "\n",
    "        # Predict partial dependence\n",
    "        pdep = gam1.partial_dependence(term=i, X=XX)\n",
    "\n",
    "        # Scatter raw data for visual context\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_test[feature],\n",
    "                y=df_test['TotalPower'],\n",
    "                mode='markers',\n",
    "                marker=dict(size=2, opacity=0.3),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "\n",
    "        # Add partial dependence line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=XX[:, i],\n",
    "                y=pdep,\n",
    "                mode='lines',\n",
    "                line=dict(color='red'),\n",
    "                name=f'PDP: {feature}',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(title_text=feature, row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Partial Effect', row=row, col=col)\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title_text=f'GAM Partial Dependence Plots ({df_train.shape[0]} train, {df_test.shape[0]} test)',\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    # Save HTML output\n",
    "    fig.write_html(f'{name_dir_export_path_PY}/reg2_gam_partial_dependence.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_optimalpv_rh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
