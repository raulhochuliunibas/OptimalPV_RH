{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d50e16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os as os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import math\n",
    "import joblib\n",
    "import copy\n",
    "import sqlite3\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from pygam import LinearGAM, s\n",
    "\n",
    "# from shapely.geometry import Point\n",
    "# from shapely.ops import unary_union\n",
    "# from dataclasses import dataclass, field\n",
    "# from typing_extensions import List, Dict, Tuple\n",
    "\n",
    "if 'scicore' in os.getcwd():\n",
    "    path = '/scicore/home/krysiak/hocrau00/ondemand/OptimalPV_RH'\n",
    "else:\n",
    "    path = os.getcwd().split('\\\\src')[0]\n",
    "    %load_ext rpy2.ipython\n",
    "\n",
    "os.chdir(path)\n",
    "from src.calibration_class import Calibration_Settings, Calibration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a68f42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dir_export_path_PY = 'c:/Models/OptimalPV_RH/data/calibration/calib_all_CH_bfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "189e0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "name_dir_export_path_R <- \"c:/Models/OptimalPV_RH/data/calibration/calib_all_CH_bfs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093c09c",
   "metadata": {},
   "source": [
    "### preprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b69ee2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    preprep_list = [\n",
    "        # Calibration_Settings(), \n",
    "\n",
    "        Calibration_Settings(\n",
    "            name_dir_export='calib_mini_debug',\n",
    "            name_preprep_subsen='bfs1201',\n",
    "            bfs_numbers=[1201,],\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False\n",
    "        ), \n",
    "        Calibration_Settings(\n",
    "            name_dir_export='calib_mini_debug',\n",
    "            name_preprep_subsen='bfs1205',\n",
    "            bfs_numbers=[1205,],\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False\n",
    "        ), \n",
    "        # Calibration_Settings(\n",
    "        #     name_dir_export='calib_mini_debug',\n",
    "        #     name_preprep_subsen='bfs96',\n",
    "        #     bfs_numbers=[96,],\n",
    "        #     rerun_import_and_preprp_data_TF = True,\n",
    "        #     export_gwr_ALL_building_gdf_TF = False\n",
    "        # ), \n",
    "        # Calibration_Settings(\n",
    "        #     name_dir_export='calib_mini_debug',\n",
    "        #     name_preprep_subsen='bfs1033',\n",
    "        #     bfs_numbers=[1033,],\n",
    "        #     rerun_import_and_preprp_data_TF = True,\n",
    "        #     export_gwr_ALL_building_gdf_TF = False\n",
    "        # ), \n",
    "    ]\n",
    "\n",
    "    for i_prep, prep_sett in enumerate(preprep_list):\n",
    "        print('')\n",
    "    #     preprep_class = Calibration(prep_sett)\n",
    "    #     preprep_class.import_and_preprep_data() if preprep_class.sett.rerun_import_and_preprp_data_TF else None\n",
    "\n",
    "    # preprep_class = Calibration(preprep_list[0])\n",
    "    # preprep_class.concatenate_prerep_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a99b6c",
   "metadata": {},
   "source": [
    "### concat preprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2e5f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "  START CALIBRATION: calib_all_CH_bfs\n",
      "  > name_preprep_subsen: preprep_class_default_sett\n",
      "  > name_calib_subscen: calib_class_default_sett\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calib_main_sett = Calibration_Settings(\n",
    "            name_dir_export='calib_all_CH_bfs',\n",
    "            scicore_concat_data_path = r'/scicore/home/krysiak/hocrau00/OptimalPV_RH/data/calibration/',\n",
    "            kt_numbers=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,], \n",
    "            # name_preprep_subsen=f'bfs{bfs_number}',\n",
    "            # bfs_numbers=[bfs_number,], \n",
    "            n_rows_import= None,\n",
    "            rerun_import_and_preprp_data_TF = True,\n",
    "            export_gwr_ALL_building_gdf_TF = False)\n",
    "calib_main = Calibration(calib_main_sett)\n",
    "# calib_main.concatenate_prerep_data()\n",
    "# calib_main.estimdf2_regression_instsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e84a8e",
   "metadata": {},
   "source": [
    "## approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524bbe33",
   "metadata": {},
   "source": [
    "### data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ebdb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weed out all inf or NaN values \n",
    "df = pd.read_csv(f'{name_dir_export_path_PY}/reg2_all_CH_bfs_df_approach2.csv')\n",
    "df = df.dropna(subset=['BFS_NUMMER', 'TotalPower', 'elecpri_Rp_kWh', 'pvtarif_Rp_kWh', 'north_max_flaeche', 'south_max_flaeche', 'east_max_flaeche', 'west_max_flaeche'])\n",
    "df.to_csv(f'{name_dir_export_path_PY}/reg2_all_CH_bfs_df_cleaned.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a64b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: <class 'UnicodeDecodeError'> 'utf-8' codec can't decode byte 0xfc in position 27: invalid start byte <traceback object at 0x00000202BDB74F80>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "if (!requireNamespace(\"readr\", quietly = TRUE)) install.packages(\"readr\")\n",
    "if (!requireNamespace(\"dplyr\", quietly = TRUE)) install.packages(\"dplyr\")\n",
    "if (!requireNamespace(\"fixest\", quietly = TRUE)) install.packages(\"fixest\")\n",
    "if (!requireNamespace(\"tibble\", quietly = TRUE)) install.packages(\"tibble\")\n",
    "if (!requireNamespace(\"jsonlite\", quietly = TRUE)) install.packages(\"jsonlite\")\n",
    "if (!requireNamespace(\"tidyr\", quietly = TRUE)) install.packages(\"tidyr\")\n",
    "if (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\n",
    "if (!requireNamespace(\"purr\", quietly = TRUE)) install.packages(\"purr\")\n",
    "if (!requireNamespace(\"tidyverse\", quietly = TRUE)) install.packages(\"tidyverse\")\n",
    "if (!requireNamespace(\"randomForest\", quietly = TRUE)) install.packages(\"randomForest\")\n",
    "\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "library(fixest)\n",
    "library(tibble)\n",
    "library(jsonlite)\n",
    "library(tidyr)\n",
    "library(ggplot2)\n",
    "library(purrr)\n",
    "library(tidyverse)\n",
    "library(randomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62b5e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 94433 Columns: 20\n",
      "-- Column specification --------------------------------------------------------\n",
      "Delimiter: \",\"\n",
      "dbl (20): EGID, year, BFS_NUMMER, xtf_id, n_DF_UID, GAREA, GBAUJ, GKLAS, GST...\n",
      "\n",
      "i Use `spec()` to retrieve the full column specification for this data.\n",
      "i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# train / test split-------------\n",
    "# train_test_split = 0.7\n",
    "\n",
    "# import -------------\n",
    "pq_files = list.files(name_dir_export_path_R, pattern = \".parquet\", full.names = TRUE)\n",
    "\n",
    "  df <- tibble(read_csv(paste0(name_dir_export_path_R, \"/reg2_all_CH_bfs_df_cleaned.csv\"), locale = locale(encoding = \"UTF-8\")))\n",
    "\n",
    "  df <- df %>% \n",
    "    mutate(\n",
    "      GBAUJ = as_factor(GBAUJ),\n",
    "      GKLAS = as_factor(GKLAS),\n",
    "      GSTAT = as_factor(GSTAT),\n",
    "      GWAERZH1 = as_factor(GWAERZH1),\n",
    "      GENH1 = as_factor(GENH1))\n",
    "\n",
    "  idx_heatpump <- df$GWAERZH1 %in% c('7410', '7411')\n",
    "  df$GWAERZH1_str <- 'no_heatpump'\n",
    "  df$GWAERZH1_str[idx_heatpump] <- 'heatpump'\n",
    "  df$GWAERZH1_str <- as_factor(df$GWAERZH1_str)\n",
    "\n",
    "\n",
    "  # split training & test data -------------\n",
    "  split_train_test <- function(df_func, df_sub_type, split_ratio = 0.7, seed = 42) {\n",
    "    set.seed(seed)\n",
    "    train_indices <- sample(1:nrow(df_func), size = split_ratio * nrow(df_func))\n",
    "    df_train_func <- df_func[train_indices, ]\n",
    "    df_test_func <- df_func[-train_indices, ]\n",
    "    \n",
    "    if (df_sub_type == \"train\"){\n",
    "      df_return = df_train_func\n",
    "    }\n",
    "    else if (df_sub_type == \"test\"){\n",
    "      df_return = df_test_func\n",
    "    }\n",
    "    else {\n",
    "      stop(\"df_sub_type must be either 'train' or 'test'\")\n",
    "    } \n",
    "    return(df_return)\n",
    "  }\n",
    "\n",
    "  df_train <- split_train_test(df, \"train\" )\n",
    "  df_test <-  split_train_test(df, \"test\"  )\n",
    "\n",
    "\n",
    "  # filter: only residential buildings -------------\n",
    "  idx_GKLAS_res3plus <- df$GKLAS %in% c(\"1110\", \"1121\", \"1122\")\n",
    "  df__res3plus <- df %>% filter(idx_GKLAS_res3plus)\n",
    "  df_train_res3plus <- split_train_test(df__res3plus, \"train\" )\n",
    "  df_test_res3plus <-  split_train_test(df__res3plus, \"test\"  )\n",
    "\n",
    "\n",
    "  idx_GKLAS_res1to2 <- df$GKLAS %in% c(\"1110\", \"1121\")\n",
    "  df__res1to2 <- df %>% filter(idx_GKLAS_res1to2)\n",
    "  df_train_res1to2 <- split_train_test(df__res1to2, \"train\" )\n",
    "  df_test_res1to2 <-  split_train_test(df__res1to2, \"test\"  )\n",
    "\n",
    "  idx_kwpmax20 <- df$TotalPower < 20\n",
    "  df__kwpmax20 <- df %>% filter(idx_kwpmax20 & idx_GKLAS_res1to2)\n",
    "  df_train_kwpmax20 <- split_train_test(df__kwpmax20, \"train\" )\n",
    "  df_test_kwpmax20 <-  split_train_test(df__kwpmax20, \"test\"  )\n",
    "\n",
    "\n",
    "  # export training & test data ------------§\n",
    "  write_csv(df_train, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_train.csv\"))\n",
    "  write_csv(df_test, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test.csv\"))\n",
    "\n",
    "  write_csv(df_train_res3plus,  paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_res3plus.csv\"))\n",
    "  write_csv(df_test_res3plus,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res3plus.csv\"))\n",
    "  write_csv(df_train_res1to2,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_res1to2.csv\"))\n",
    "  write_csv(df_test_res1to2,    paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res1to2.csv\" ))\n",
    "  write_csv(df_train_kwpmax20,  paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_train_kwpmax20.csv\"))\n",
    "  write_csv(df_test_kwpmax20,   paste0(getwd(),  \"/data/calibration/calib_all_CH_bfs/reg2_df_test_kwpmax20.csv\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d680b26",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54084fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n",
       "NOTE: 1/0 fixed-effect singleton was removed (1 observation).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "# fit regression model\n",
    "fe11 <- feols( TotalPower ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche, data = df_train )\n",
    "fe12 <- feols( TotalPower ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche | year, data = df_train    )\n",
    "\n",
    "fe13 <- feols( TotalPower ~\n",
    "    elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "    west_max_flaeche + south_max_flaeche + east_max_flaeche |\n",
    "    BFS_NUMMER,\n",
    "    data = df_train\n",
    "    )\n",
    "df_test$pred_fe13 <- predict(fe13, newdata = df_test)\n",
    "\n",
    "fe14 <- feols( TotalPower ~\n",
    "    elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "    west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "    BFS_NUMMER + year,\n",
    "    data = df_train\n",
    "    )\n",
    "df_test$pred_fe14 <- predict(fe14, newdata = df_test)\n",
    "\n",
    "fe21 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train\n",
    ")\n",
    "df_test$pred_fe21 <- predict(fe21, newdata = df_test)\n",
    "\n",
    "fe24a <- feols(log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh +west_max_flaeche + south_max_flaeche + east_max_flaeche, data = df_train)\n",
    "fe24b <- feols( log(TotalPower) ~  elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche |  year,  data = df_train )\n",
    "\n",
    "fe24c<- feols(\n",
    "    log(TotalPower) ~ \n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER, \n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe24c <- predict(fe24c, newdata = df_test)\n",
    "\n",
    "fe24d<- feols(\n",
    "    log(TotalPower) ~ \n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe24d <- predict(fe24d, newdata = df_test)\n",
    "\n",
    "fe25a<- feols(log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh +west_max_flaeche + south_max_flaeche + east_max_flaeche,data = df_train)\n",
    "fe25b<- feols( log(TotalPower) ~ elecpri_Rp_kWh + pvtarif_Rp_kWh + west_max_flaeche + south_max_flaeche + east_max_flaeche |  year, data = df_train)\n",
    "fe25c<- feols(\n",
    "    log(TotalPower) ~\n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe25c <- predict(fe25c, newdata = df_test)\n",
    "\n",
    "fe25d<- feols(\n",
    "    log(TotalPower) ~\n",
    "      elecpri_Rp_kWh + pvtarif_Rp_kWh +\n",
    "      west_max_flaeche + south_max_flaeche + east_max_flaeche | \n",
    "      BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe25d <- predict(fe25d, newdata = df_test)\n",
    "\n",
    "fe26a <- feols( log(TotalPower) ~  elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) + pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + west_max_flaeche + I(west_max_flaeche^2) + south_max_flaeche + I(south_max_flaeche^2) + east_max_flaeche + I(east_max_flaeche^2), data = df_train)\n",
    "fe26b <- feols( log(TotalPower) ~  elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) + pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + west_max_flaeche + I(west_max_flaeche^2) + south_max_flaeche + I(south_max_flaeche^2) + east_max_flaeche + I(east_max_flaeche^2) | year, data = df_train )\n",
    "fe26c <- feols(\n",
    "    log(TotalPower) ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe26c <- predict(fe26c, newdata = df_test)\n",
    "\n",
    "fe26d <- feols(\n",
    "    log(TotalPower) ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) +\n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "    data = df_train\n",
    ")\n",
    "df_test$pred_fe26d <- predict(fe26d, newdata = df_test)\n",
    "\n",
    "\n",
    "# only residential buildings of small size\n",
    "fe30 <-  feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train\n",
    ")\n",
    "df_test$pred_fe30 <- predict(fe30, newdata = df_test)\n",
    "\n",
    "fe31 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res3plus\n",
    ")\n",
    "df_test_res3plus$pred_fe31 <- predict(fe31, newdata = df_test_res3plus) \n",
    "\n",
    "fe32 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    west_max_flaeche + I(west_max_flaeche^2) +\n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    east_max_flaeche + I(east_max_flaeche^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res1to2\n",
    ")\n",
    "df_test_res1to2$pred_fe32 <- predict(fe32, newdata = df_test_res1to2)\n",
    "\n",
    "fe40 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    FLAECHE_total + I(FLAECHE_total^2) |\n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res3plus\n",
    ")\n",
    "df_test_res3plus$pred_fe40 <- predict(fe40, newdata = df_test_res3plus)\n",
    "\n",
    "fe41 <- feols(\n",
    "  TotalPower ~ \n",
    "    elecpri_Rp_kWh + I(elecpri_Rp_kWh^2) +\n",
    "    pvtarif_Rp_kWh + I(pvtarif_Rp_kWh^2) + \n",
    "    GBAUJ + GKLAS + GSTAT + GWAERZH1_str + \n",
    "    south_max_flaeche + I(south_max_flaeche^2) +\n",
    "    FLAECHE_total + I(FLAECHE_total^2) |  \n",
    "    BFS_NUMMER + year,\n",
    "  data = df_train_res1to2\n",
    ")\n",
    "df_test_res1to2$pred_fe41 <- predict(fe41, newdata = df_test_res1to2)\n",
    "\n",
    "\n",
    "write_csv(df_test, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test.csv\"))\n",
    "write_csv(df_test_res3plus, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res3plus.csv\"))\n",
    "write_csv(df_test_res1to2, paste0(getwd(), \"/data/calibration/calib_all_CH_bfs/reg2_df_test_res1to2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c7b6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "fe_model_list <- list(\n",
    "  fe11 = fe11, fe12 = fe12, fe13 = fe13, fe14 = fe14, \n",
    "  fe21 = fe21, \n",
    "  # fe22 = fe22, fe23 = fe23,\n",
    "  fe24a = fe24a, fe24b = fe24b, fe24c = fe24c, fe24d = fe24d, \n",
    "  fe25a = fe25a, fe25b = fe25b, fe25c = fe25c, fe25d = fe25d,\n",
    "  fe26a = fe26a, fe26b = fe26b, fe26c = fe26c, fe26d = fe26d,\n",
    "  fe30 = fe30, fe31 = fe31,\n",
    "  fe40 = fe40, fe41 = fe41\n",
    ")\n",
    "\n",
    "# Export model info as a named list\n",
    "model_export <- lapply(fe_model_list, function(model) {\n",
    "  list(\n",
    "    comment = paste(deparse(formula(model)), collapse = \" \"),\n",
    "    coefficients = coef(model)\n",
    "  )\n",
    "})\n",
    "\n",
    "# Write JSON with model names as top-level keys\n",
    "write_json(\n",
    "  model_export,\n",
    "  path = file.path(getwd(), \"data/calibration/calib_all_CH_bfs/reg2_fe_model_coef.json\"),\n",
    "  pretty = TRUE,\n",
    "  auto_unbox = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcfc62",
   "metadata": {},
   "source": [
    "### ML random forest regression - full sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a666cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest_regression(rfr_mod_name, df_suffix, rfr_settings):\n",
    "\n",
    "    # import\n",
    "    df_train_rfr = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train{df_suffix}.csv')\n",
    "    df_test_rfr  = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}.csv')\n",
    "\n",
    "    old_pred_cols = [col for col in df_test_rfr.columns if 'pred_' in col]\n",
    "    df_test_rfr_old = df_test_rfr[old_pred_cols + ['EGID', ]].copy()\n",
    "\n",
    "\n",
    "    # transformations\n",
    "    # df_train_rfr = df_train_rfr.drop(columns=['EGID', 'xtf_id', 'n_DF_UID']).copy()\n",
    "    cols_dtypes_tupls = {\n",
    "        # 'year': 'int64',\n",
    "        'BFS_NUMMER': 'category',\n",
    "        'GAREA': 'float64',\n",
    "        # 'GBAUJ': 'int64',   \n",
    "        'GKLAS': 'category',\n",
    "        # 'GSTAT': 'category',\n",
    "        'GWAERZH1': 'category',\n",
    "        'GENH1': 'category',\n",
    "        'GWAERZH1_str': 'category',\n",
    "        # 'InitialPower': 'float64',\n",
    "        'TotalPower': 'float64',\n",
    "        'elecpri_Rp_kWh': 'float64',\n",
    "        'pvtarif_Rp_kWh': 'float64',\n",
    "        'FLAECHE_total': 'float64',\n",
    "        'east_max_flaeche': 'float64',\n",
    "        'west_max_flaeche': 'float64',\n",
    "        'north_max_flaeche': 'float64',\n",
    "        'south_max_flaeche': 'float64',\n",
    "    }\n",
    "    df_train_rfr = df_train_rfr[[col for col in cols_dtypes_tupls.keys() if col in df_train_rfr.columns]].copy()\n",
    "    df_test_rfr = df_test_rfr[[col for col in cols_dtypes_tupls.keys() if col in df_test_rfr.columns]].copy()\n",
    "\n",
    "    df_train_rfr = df_train_rfr.dropna().copy()\n",
    "    df_test_rfr = df_test_rfr.dropna().copy()\n",
    "\n",
    "\n",
    "    for col, dtype in cols_dtypes_tupls.items():\n",
    "        df_train_rfr[col] = df_train_rfr[col].astype(dtype)\n",
    "        df_test_rfr[col]  = df_test_rfr[col].astype(dtype)\n",
    "\n",
    "    X = df_train_rfr.drop(columns=['TotalPower', ])\n",
    "    y = df_train_rfr['TotalPower']\n",
    "\n",
    "    # encode categorical variables\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_Arry = encoder.fit_transform(X[cat_cols].astype(str))\n",
    "    encoded_df = pd.DataFrame(encoded_Arry, columns=encoder.get_feature_names_out(cat_cols))\n",
    "    X = pd.concat([X.drop(columns=cat_cols).reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "    # rf model\n",
    "    if rfr_settings['run_ML_rfr_TF']:\n",
    "        # rfr_model = RandomForestRegressor(\n",
    "        #     n_estimators   = rfr_settings['n_estimators'],\n",
    "        #     max_depth      = rfr_settings['max_depth'],\n",
    "        #     random_state   = rfr_settings['random_state'],\n",
    "        #     n_jobs         = rfr_settings['n_jobs'],\n",
    "        # )\n",
    "        # # cross validation\n",
    "        # kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        # cv_scores = cross_val_score(rfr_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "        # rfr_model.fit(X, y)\n",
    "\n",
    "        rfr_model = RandomForestRegressor(random_state = rfr_settings['random_state'])\n",
    "        param_grid = {\n",
    "            'n_estimators':      rfr_settings['n_estimators'],\n",
    "            'min_samples_split': rfr_settings['min_samples_split'],\n",
    "            'max_depth':         rfr_settings['max_depth'],\n",
    "        }\n",
    "            \n",
    "        grid_search = GridSearchCV(\n",
    "            rfr_model,\n",
    "            param_grid,\n",
    "            cv=rfr_settings['cross_validation'],\n",
    "            scoring='neg_mean_absolute_error',\n",
    "            n_jobs=rfr_settings['n_jobs'],\n",
    "            return_train_score=True,\n",
    "        )\n",
    "        grid_search.fit(X, y)\n",
    "        rfr_model = grid_search.best_estimator_\n",
    "\n",
    "        # save model\n",
    "        joblib.dump(rfr_model, f'{name_dir_export_path_PY}/reg2_{rfr_mod_name}_model.pkl')\n",
    "        joblib.dump(encoder, f'{name_dir_export_path_PY}/reg2_{rfr_mod_name}_encoder.pkl')\n",
    "\n",
    "\n",
    "    # prediction\n",
    "    if rfr_settings['run_ML_rfr_TF']:\n",
    "        X_test = df_test_rfr.drop(columns=['TotalPower', ])\n",
    "        encoded_test_array = encoder.transform(X_test[cat_cols].astype(str))\n",
    "        encoded_test_df = pd.DataFrame(encoded_test_array, columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "        X_test_final = pd.concat([X_test.drop(columns=cat_cols).reset_index(drop=True), encoded_test_df.reset_index(drop=True)], axis=1)\n",
    "        X_test_final = X_test_final[X.columns]\n",
    "\n",
    "        test_preds = rfr_model.predict(X_test_final)\n",
    "\n",
    "        df_test_rfr[f'pred_{rfr_mod_name}'] = test_preds\n",
    "\n",
    "    else: \n",
    "        df_test_rfr[f'pred_{rfr_mod_name}'] = np.zeros(df_test_rfr.shape[0])\n",
    "\n",
    "    df_test_rfr.to_csv(f'{name_dir_export_path_PY}/reg2_df_test{df_suffix}_RFR.csv', index=False)\n",
    "\n",
    "    del df_train_rfr, df_test_rfr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e88d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ML_rfr_TF = True\n",
    "rfr_settings = {\n",
    "    'comment_settings_RandomForestRegressor()': \n",
    "        \"\"\"\n",
    "        n_estimators:       Defines the number of decision trees in the Random Forest.\n",
    "        random_state=0:     Ensures the randomness in model training is controlled for reproducibility.\n",
    "        oob_score=True:     Enables out-of-bag scoring which evaluates the model's performance using data \n",
    "                            not seen by individual trees during training\n",
    "        max_depth:          The maximum depth of the tree. If None, then nodes are expanded until all \n",
    "                            leaves are pure or until all leaves contain less than min_samples_split \n",
    "                            samples\n",
    "\n",
    "    \"\"\",\n",
    "    'run_ML_rfr_TF':        True,\n",
    "    'random_state':         None,    # default: None  # | None,    \n",
    "    'n_jobs':               -1,      # default: None  # | -1,      \n",
    "    'cross_validation':     2, \n",
    "    'n_estimators':         [100, ]  ,    # default: 100   # | 1,       \n",
    "    'min_samples_split':    [5, ]    ,    # default: 2     # | 1000,    \n",
    "    'max_depth':            [20, ]   ,    # default: None  # | 3,       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a61abb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_random_forest_regression(rfr_mod_name='local_nb_rfr1', df_suffix='',             rfr_settings=rfr_settings)\n",
    "# run_random_forest_regression(rfr_mod_name='local_nb_rfr2', df_suffix='_kwpmax20',    rfr_settings=rfr_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d8ee5",
   "metadata": {},
   "source": [
    "### GAM - Generalized Additive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90521dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train.csv')\n",
    "df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "            'north_max_flaeche', 'south_max_flaeche',\n",
    "            'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "x_train = df_train[features].values\n",
    "y_train = df_train['TotalPower'].values\n",
    "\n",
    "x_test = df_test[features].values\n",
    "y_test = df_test['TotalPower'].values\n",
    "\n",
    "gam1 = LinearGAM(\n",
    "    s(0) + s(1) + s(2) + s(3) + s(4) + s(5)\n",
    ").fit(x_train, y_train)\n",
    "y_pred_gam1 = gam1.predict(x_train)\n",
    "df_test['pred_gam1'] = gam1.predict(x_test)\n",
    "\n",
    "# export coefs and df_test\n",
    "model_formula = \"TotalPower ~ s(elecpri_Rp_kWh) + s(pvtarif_Rp_kWh) + s(north_max_flaeche) + s(south_max_flaeche) + s(east_max_flaeche) + s(west_max_flaeche)\"\n",
    "coefficients = gam1.coef_.tolist()\n",
    "lambdas = list(gam1.lam)\n",
    "terms = [str(gam1.terms[i]) for i in range(len(gam1.terms))]\n",
    "reg2_gam_model_coef = {\n",
    "    \"comment\": model_formula,\n",
    "    \"coefficients\": coefficients,\n",
    "    \"lambdas\": lambdas,\n",
    "    \"terms\": terms\n",
    "}\n",
    "with open(f'{name_dir_export_path_PY}/reg2_gam_model_coef.json', 'w') as f:\n",
    "    json.dump(reg2_gam_model_coef, f, indent=4)\n",
    "\n",
    "df_test.to_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41821458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_res1to2 =  pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train_res1to2.csv')\n",
    "df_test_res1to2 =   pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv' )\n",
    "\n",
    "features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "            'north_max_flaeche', 'south_max_flaeche',\n",
    "            'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "x_train = df_train_res1to2[features].values\n",
    "y_train = df_train_res1to2['TotalPower'].values\n",
    "\n",
    "x_test = df_test_res1to2[features].values\n",
    "y_test = df_test_res1to2['TotalPower'].values\n",
    "\n",
    "gam2 = LinearGAM(\n",
    "    s(0) + s(1) + s(2) + s(3) + s(4) + s(5)\n",
    ").fit(x_train, y_train)\n",
    "y_pred_gam2 = gam2.predict(x_train)\n",
    "df_test_res1to2['pred_gam2'] = gam2.predict(x_test)\n",
    "\n",
    "# export coefs and df_test\n",
    "model_formula = \"TotalPower ~ s(elecpri_Rp_kWh) + s(pvtarif_Rp_kWh) + s(north_max_flaeche) + s(south_max_flaeche) + s(east_max_flaeche) + s(west_max_flaeche)\"\n",
    "coefficients = gam2.coef_.tolist()\n",
    "lambdas = list(gam2.lam)\n",
    "terms = [str(gam2.terms[i]) for i in range(len(gam2.terms))]\n",
    "reg2_gam_model_coef = {\n",
    "    \"comment\": model_formula,\n",
    "    \"coefficients\": coefficients,\n",
    "    \"lambdas\": lambdas,\n",
    "    \"terms\": terms\n",
    "}\n",
    "with open(f'{name_dir_export_path_PY}/reg2_gam_model_coef.json', 'w') as f:\n",
    "    json.dump(reg2_gam_model_coef, f, indent=4)\n",
    "\n",
    "df_test_res1to2.to_csv(f'{name_dir_export_path_PY}/reg2_df_test_res1to2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fd345",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbee4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d144886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION ACCURACY PLOTS\n",
    "if True: \n",
    "    pred_colname_dfname_tuples = [\n",
    "        ('pred_fe21', 'reg2_df_test.csv'),\n",
    "        ('pred_fe31', 'reg2_df_test_res3plus.csv'),\n",
    "        ('pred_fe32', 'reg2_df_test_res1to2.csv'),\n",
    "        ('pred_fe40', 'reg2_df_test_res3plus.csv'),\n",
    "        ('pred_fe41', 'reg2_df_test_res1to2.csv'),\n",
    "        ('pred_local_nb_rfr1', 'reg2_df_test_RFR.csv'),\n",
    "        ('pred_local_nb_rfr2', 'reg2_df_test_kwpmax20_RFR.csv'),\n",
    "        ('pred_rfr1', 'df_test_rfr_rfr1.csv'),\n",
    "        ('pred_rfr2', 'df_test_rfr_rfr2.csv'),\n",
    "    ]\n",
    "\n",
    "    # accuracy plot ------------\n",
    "    pred_cols = [tup[0] for tup in pred_colname_dfname_tuples]\n",
    "    ncols = 3\n",
    "    nplots = len (pred_cols)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "    fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=pred_cols, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "    for i, (pred_col, df_name) in enumerate(pred_colname_dfname_tuples):\n",
    "        row = (i // ncols) + 1\n",
    "        col = (i % ncols) + 1\n",
    "\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/{df_name}')\n",
    "\n",
    "        df_import = df_import.dropna(subset=[pred_col, 'TotalPower'])    \n",
    "        df_accu = df_import.replace([np.inf, -np.inf], np.nan).dropna(subset=['TotalPower', pred_col]).copy()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_accu[pred_col],\n",
    "                y=df_accu['TotalPower'],\n",
    "                mode='markers',\n",
    "                marker=dict(size=3, opacity=0.5),\n",
    "                name=pred_col,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        # add diagonal line y=x\n",
    "        min_val = min(df_accu['TotalPower'].min(), df_accu[pred_col].min()) * 0.95\n",
    "        max_val = max(df_accu['TotalPower'].max(), df_accu[pred_col].max()) * 1.05\n",
    "        fig.add_trace(go.Scatter(x=[min_val, max_val],\n",
    "                                    y=[min_val, max_val],\n",
    "                                    mode='lines',\n",
    "                                    line=dict(color='red', dash='dash'),\n",
    "                                    name='Perfect Prediction',\n",
    "                                    showlegend=False),\n",
    "                        row=row, col=col)\n",
    "\n",
    "        fig.update_xaxes(title_text=f'PredPwr {df_accu.shape[0]}n', row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "    # layout \n",
    "    fig.update_layout(\n",
    "        # height=300 * nrows, width=1000,\n",
    "                    title_text=f'Predicted Power vs Total Power ({df_accu.shape[0]} n_df_train, {df_accu.shape[0]} n_df_test)',\n",
    "                    plot_bgcolor='white')\n",
    "    for i in range(1, nplots + 1):\n",
    "        row = (i - 1) // ncols + 1\n",
    "        col = (i - 1) % ncols + 1\n",
    "        # fig.update_xaxes(title_text='Predicted Power', row=row, col=col)\n",
    "        # fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "    fig.write_html(f'{name_dir_export_path_PY}/reg2_pred_vs_total_power.html')\n",
    "\n",
    "\n",
    "    # RMSE plot ------------\n",
    "    rmse_dict = {}\n",
    "\n",
    "    for i, (pred_col, df_name) in enumerate(pred_colname_dfname_tuples):\n",
    "\n",
    "        df_import = pd.read_csv(f'{name_dir_export_path_PY}/{df_name}') \n",
    "\n",
    "        df_import = df_import.dropna(subset=[pred_col, 'TotalPower'])    \n",
    "        df_accu = df_import.replace([np.inf, -np.inf], np.nan).dropna(subset=['TotalPower', pred_col]).copy()\n",
    "        \n",
    "        rmse = mean_squared_error(df_accu['TotalPower'], df_accu[pred_col])\n",
    "        rmse_dict[pred_col] = rmse\n",
    "\n",
    "    bar_fig = go.Figure()\n",
    "\n",
    "    bar_fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=list(rmse_dict.keys()),\n",
    "            y=list(rmse_dict.values()),\n",
    "            marker=dict(color='cornflowerblue'),\n",
    "            text=[f\"{v:.2f}\" for v in rmse_dict.values()],\n",
    "            textposition='auto'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    bar_fig.update_layout(\n",
    "        title='RMSE of Model Predictions on Test Set',\n",
    "        xaxis_title='Model',\n",
    "        yaxis_title='RMSE',\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    # Save bar plot\n",
    "    bar_fig.write_html(f'{name_dir_export_path_PY}/reg2_rmse_barplot.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1493956",
   "metadata": {},
   "source": [
    "## explore missing pvs in reg2\n",
    "find out more about (huge) amount of missing pv inst in `reg2_all_CH_bfs_df_approach2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON PV IN ESTIMATING SAMPLE \n",
    "\n",
    "# gm_shp_gdf\n",
    "# gm_shp_gdf = gpd.read_file(f'{self.sett.data_path}/input/swissboundaries3d_2023-01_2056_5728.shp', layer ='swissBOUNDARIES3D_1_4_TLM_HOHEITSGEBIET')\n",
    "gm_shp_gdf = gpd.read_file(R\"C:\\Models\\OptimalPV_RH\\data\\input\\swissboundaries3d_2023-01_2056_5728.shp\\swissBOUNDARIES3D_1_4_TLM_HOHEITSGEBIET.shp\", layer ='swissBOUNDARIES3D_1_4_TLM_HOHEITSGEBIET')\n",
    "gm_shp_gdf = gm_shp_gdf.drop(columns = ['DATUM_AEND', 'DATUM_ERST'])\n",
    "gm_shp_gdf = gm_shp_gdf.loc[gm_shp_gdf['KANTONSNUM'].notna()]\n",
    "gm_shp_gdf['KANTONSNUM'] = gm_shp_gdf['KANTONSNUM'].astype(int)\n",
    "gm_shp_gdf['BFS_NUMMER'] = gm_shp_gdf['BFS_NUMMER'].astype(str)\n",
    "gm_shp_gdf.crs = 'EPSG:2056'\n",
    "\n",
    "def attach_bfs_to_spatial_data(gdf, gm_shp_df, keep_cols = ['BFS_NUMMER', 'geometry' ]):\n",
    "    \"\"\"\n",
    "    Function to attach BFS numbers to spatial data sources\n",
    "    \"\"\"\n",
    "    gdf = copy.deepcopy(gdf)\n",
    "    gdf.set_crs(gm_shp_df.crs, allow_override=True, inplace=True)\n",
    "    gdf = gpd.sjoin(gdf, gm_shp_df, how=\"left\", predicate=\"within\")\n",
    "    dele_cols = ['index_right'] + [col for col in gm_shp_df.columns if col not in keep_cols]\n",
    "    gdf.drop(columns = dele_cols, inplace = True)\n",
    "    if 'BFS_NUMMER' in gdf.columns:\n",
    "        # transform BFS_NUMMER to str, np.nan to ''\n",
    "        gdf['BFS_NUMMER'] = gdf['BFS_NUMMER'].apply(lambda x: '' if pd.isna(x) else str(int(x)))\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# import rfr \n",
    "rfr_pl = pl.read_csv(r\"C:\\Models\\OptimalPV_RH\\data\\calibration\\PVALLOC_calibration_model_coefs\\reg2_all_CH_bfs_df_approach2.csv\")\n",
    "rfr_pl = rfr_pl.with_columns([\n",
    "    pl.col('xtf_id').cast(pl.Utf8),\n",
    "    pl.col('BFS_NUMMER').cast(pl.Utf8),\n",
    "    pl.col('GKLAS').cast(pl.Utf8),\n",
    "    pl.col('GSTAT').cast(pl.Utf8),\n",
    "    pl.col('GWAERZH1').cast(pl.Utf8),\n",
    "])\n",
    "\n",
    "\n",
    "# import pv\n",
    "elec_prod_gdf = gpd.read_file(\n",
    "    r\"C:\\Models\\OptimalPV_RH\\data\\input\\ch.bfe.elektrizitaetsproduktionsanlagen_gpkg\\ch.bfe.elektrizitaetsproduktionsanlagen.gpkg\",\n",
    "    layer ='ElectricityProductionPlant', \n",
    "    )\n",
    "pv_all_gdf = elec_prod_gdf.loc[elec_prod_gdf['SubCategory'] == 'subcat_2'].copy()\n",
    "pv_all_gdf['xtf_id'] = pv_all_gdf['xtf_id'].astype(str)\n",
    "pv_all_gdf = attach_bfs_to_spatial_data(pv_all_gdf, gm_shp_gdf)\n",
    "pv_all_pl = pl.DataFrame(pv_all_gdf.drop(columns='geometry'))\n",
    "\n",
    "\n",
    "# import gwr\n",
    "query_columns = ['EGID', 'GDEKT', 'GGDENR', 'GKODE', 'GKODN', 'GKSCE', 'GSTAT', 'GKAT', 'GKLAS', 'GBAUJ', 'GBAUM', 'GBAUP', 'GABBJ', 'GANZWHG','GWAERZH1', 'GENH1', 'GWAERSCEH1', 'GWAERDATH1', 'GEBF', 'GAREA']\n",
    "query_columns_str = ', '.join(query_columns)\n",
    "query_bfs_numbers = ', '.join([str(i) for i in self.sett.bfs_numbers])\n",
    "\n",
    "conn = sqlite3.connect(r\"C:\\Models\\OptimalPV_RH\\data\\input/GebWohnRegister.CH/data.sqlite\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(f'SELECT {query_columns_str} FROM building')\n",
    "sqlrows = cur.fetchall()\n",
    "conn.close()\n",
    "\n",
    "gwr_all_building_df = pd.DataFrame(sqlrows, columns=query_columns)\n",
    "\n",
    "def gwr_to_gdf(df):\n",
    "    df = copy.deepcopy(df)                \n",
    "    df = df.loc[(df['GKODE'] != '') & (df['GKODN'] != '')]\n",
    "    df[['GKODE', 'GKODN']] = df[['GKODE', 'GKODN']].astype(float)\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['GKODE'], row['GKODN']), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    gdf.crs = 'EPSG:2056'\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "798b0df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_pv not in calibration: 93.1% -> 222661 not in rfr of 239214 pv_all_pl installations\n",
      "n_bfs completely left out (n_pv in gm == n_pv not in rfr): 58.1% -> 1249 of 2149 bfs areas\n"
     ]
    }
   ],
   "source": [
    "# print('pv_all_pl')\n",
    "# for col in pv_all_pl.columns:\n",
    "#     print(f'{col:25} type: {pv_all_pl[col].dtype}')\n",
    "\n",
    "# print('\\nrfr_pl')\n",
    "# for col in rfr_pl.columns:\n",
    "#     print(f'{col:25} type: {rfr_pl[col].dtype}')\n",
    "\n",
    "pv_not_rfr = pv_all_pl.filter(~pl.col('xtf_id').is_in(rfr_pl['xtf_id'].implode()))\n",
    "\n",
    "print(f'n_pv not in calibration: {pv_not_rfr.shape[0]/pv_all_pl.shape[0]*100:.1f}% -> {pv_not_rfr.shape[0]} not in rfr of {pv_all_pl.shape[0]} pv_all_pl installations')\n",
    "bfs_list, n_pv_bfs_list, n_pv_not_rfr_bfs_list, share_pv_not_rfr_list = [], [], [], []\n",
    "for bfs_num in gm_shp_gdf['BFS_NUMMER'].unique():\n",
    "    n_pv_bfs = pv_all_pl.filter(pl.col('BFS_NUMMER') == bfs_num).shape[0]\n",
    "    n_pv_not_rfr_bfs = pv_not_rfr.filter(pl.col('BFS_NUMMER') == bfs_num).shape[0]\n",
    "\n",
    "    bfs_list.append(bfs_num)\n",
    "    n_pv_bfs_list.append(n_pv_bfs)\n",
    "    n_pv_not_rfr_bfs_list.append(n_pv_not_rfr_bfs)\n",
    "    share_pv_not_rfr_list.append(n_pv_not_rfr_bfs / n_pv_bfs if n_pv_bfs > 0 else 0)\n",
    "\n",
    "bfs_pv_nan_df = pd.DataFrame({\n",
    "    'BFS_NUMMER': bfs_list,\n",
    "    'n_pv_bfs': n_pv_bfs_list,\n",
    "    'n_pv_not_rfr_bfs': n_pv_not_rfr_bfs_list,\n",
    "    'share_pv_not_rfr': share_pv_not_rfr_list,\n",
    "    })\n",
    "print(f'n_bfs completely left out (n_pv in gm == n_pv not in rfr): {bfs_pv_nan_df.loc[bfs_pv_nan_df[\"n_pv_bfs\"] == bfs_pv_nan_df[\"n_pv_not_rfr_bfs\"]].shape[0]/bfs_pv_nan_df.shape[0]*100:.1f}% -> {bfs_pv_nan_df.loc[bfs_pv_nan_df[\"n_pv_bfs\"] == bfs_pv_nan_df[\"n_pv_not_rfr_bfs\"]].shape[0]} of {bfs_pv_nan_df.shape[0]} bfs areas')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "693d0864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>xtf_id</th><th>Address</th><th>PostCode</th><th>Municipality</th><th>Canton</th><th>BeginningOfOperation</th><th>InitialPower</th><th>TotalPower</th><th>MainCategory</th><th>SubCategory</th><th>PlantCategory</th><th>BFS_NUMMER</th></tr><tr><td>str</td><td>str</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;10797&quot;</td><td>&quot;Brüggelbachstrasse 9&quot;</td><td>3176</td><td>&quot;Neuenegg&quot;</td><td>&quot;BE&quot;</td><td>&quot;2008-11-20&quot;</td><td>12.5</td><td>12.5</td><td>&quot;maincat_2&quot;</td><td>&quot;subcat_2&quot;</td><td>&quot;plantcat_9&quot;</td><td>&quot;670&quot;</td></tr><tr><td>&quot;11795&quot;</td><td>&quot;Via Industria 1&quot;</td><td>6934</td><td>&quot;Bioggio&quot;</td><td>&quot;TI&quot;</td><td>&quot;2009-08-17&quot;</td><td>124.199997</td><td>1541.079956</td><td>&quot;maincat_2&quot;</td><td>&quot;subcat_2&quot;</td><td>&quot;plantcat_8&quot;</td><td>&quot;5151&quot;</td></tr><tr><td>&quot;14763&quot;</td><td>&quot;Kürzematt 12&quot;</td><td>4515</td><td>&quot;Oberdorf SO&quot;</td><td>&quot;SO&quot;</td><td>&quot;2009-12-07&quot;</td><td>6.3</td><td>6.3</td><td>&quot;maincat_2&quot;</td><td>&quot;subcat_2&quot;</td><td>&quot;plantcat_8&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;14764&quot;</td><td>&quot;Winkel&quot;</td><td>4234</td><td>&quot;Zullwil&quot;</td><td>&quot;SO&quot;</td><td>&quot;2008-11-07&quot;</td><td>3.2</td><td>3.2</td><td>&quot;maincat_2&quot;</td><td>&quot;subcat_2&quot;</td><td>&quot;plantcat_8&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;14775&quot;</td><td>&quot;Katzacker 9&quot;</td><td>3368</td><td>&quot;Bleienbach&quot;</td><td>&quot;BE&quot;</td><td>&quot;2009-11-25&quot;</td><td>4.2</td><td>4.2</td><td>&quot;maincat_2&quot;</td><td>&quot;subcat_2&quot;</td><td>&quot;plantcat_8&quot;</td><td>&quot;324&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 12)\n",
       "┌────────┬────────────┬──────────┬────────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ xtf_id ┆ Address    ┆ PostCode ┆ Municipali ┆ … ┆ MainCatego ┆ SubCatego ┆ PlantCate ┆ BFS_NUMME │\n",
       "│ ---    ┆ ---        ┆ ---      ┆ ty         ┆   ┆ ry         ┆ ry        ┆ gory      ┆ R         │\n",
       "│ str    ┆ str        ┆ i32      ┆ ---        ┆   ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│        ┆            ┆          ┆ str        ┆   ┆ str        ┆ str       ┆ str       ┆ str       │\n",
       "╞════════╪════════════╪══════════╪════════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 10797  ┆ Brüggelbac ┆ 3176     ┆ Neuenegg   ┆ … ┆ maincat_2  ┆ subcat_2  ┆ plantcat_ ┆ 670       │\n",
       "│        ┆ hstrasse 9 ┆          ┆            ┆   ┆            ┆           ┆ 9         ┆           │\n",
       "│ 11795  ┆ Via        ┆ 6934     ┆ Bioggio    ┆ … ┆ maincat_2  ┆ subcat_2  ┆ plantcat_ ┆ 5151      │\n",
       "│        ┆ Industria  ┆          ┆            ┆   ┆            ┆           ┆ 8         ┆           │\n",
       "│        ┆ 1          ┆          ┆            ┆   ┆            ┆           ┆           ┆           │\n",
       "│ 14763  ┆ Kürzematt  ┆ 4515     ┆ Oberdorf   ┆ … ┆ maincat_2  ┆ subcat_2  ┆ plantcat_ ┆           │\n",
       "│        ┆ 12         ┆          ┆ SO         ┆   ┆            ┆           ┆ 8         ┆           │\n",
       "│ 14764  ┆ Winkel     ┆ 4234     ┆ Zullwil    ┆ … ┆ maincat_2  ┆ subcat_2  ┆ plantcat_ ┆           │\n",
       "│        ┆            ┆          ┆            ┆   ┆            ┆           ┆ 8         ┆           │\n",
       "│ 14775  ┆ Katzacker  ┆ 3368     ┆ Bleienbach ┆ … ┆ maincat_2  ┆ subcat_2  ┆ plantcat_ ┆ 324       │\n",
       "│        ┆ 9          ┆          ┆            ┆   ┆            ┆           ┆ 8         ┆           │\n",
       "└────────┴────────────┴──────────┴────────────┴───┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# charactersitics of pv in bfs which are not completely omitted\n",
    "bfs_complete_nan = bfs_pv_nan_df.loc[bfs_pv_nan_df['share_pv_not_rfr'] == 1.0, 'BFS_NUMMER'].tolist()\n",
    "pv2 = pv_all_pl.filter( \n",
    "    (~pl.col('BFS_NUMMER').is_in(bfs_complete_nan)) & \n",
    "    (~pl.col('xtf_id').is_in(rfr_pl['xtf_id'].implode()))\n",
    "    )\n",
    "pv2.shape\n",
    "pv2.head()\n",
    "\n",
    "# print(f'n_pv not in calibration (only bfs with at least one pv in rfr): \n",
    "# bfs_pv_nan_df = pl.DataFrame(bfs_pv_nan_dict).transpose().with_columns([\n",
    "#     pl.col('n_pv_bfs').cast(pl.Int64),\n",
    "#     pl.col('n_pv_not_rfr_bfs').cast(pl.Int64),\n",
    "#     pl.col('share_pv_not_rfr').cast(pl.Float64),    \n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a16aa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SUMMARY BAR PLOTS\n",
    "# df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "# cols_to_plot_tupls = [\n",
    "#     ('GAREA',              'float',   30  ), \n",
    "#     ('GBAUJ',              'str',     30  ), \n",
    "#     ('GKLAS',              'str',     30  ), \n",
    "#     ('GSTAT',              'str',     30  ), \n",
    "#     ('GENH1',              'str',     30  ), \n",
    "#     ('GWAERZH1',           'str',     30  ), \n",
    "#     ('FLAECHE_total',     'float',    30  ),\n",
    "#     ('elecpri_Rp_kWh',     'float',   30  ), \n",
    "#     ('TotalPower',         'float',   30  ), \n",
    "#     ('pvtarif_Rp_kWh',     'float',   30  ), \n",
    "#     ('west_max_flaeche',   'float',   30  ), \n",
    "#     ('east_max_flaeche',   'float',   30  ), \n",
    "#     ('south_max_flaeche',  'float',   30  ), \n",
    "# ]\n",
    "\n",
    "# ncols = 3\n",
    "# nplots = len (cols_to_plot_tupls)\n",
    "# nrows = math.ceil(nplots / ncols)\n",
    "# subplot_titles = [col for col, _, _ in cols_to_plot_tupls]\n",
    "# fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=subplot_titles, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "# for i, (col, col_type, col_nbins) in enumerate(cols_to_plot_tupls):\n",
    "#     row = (i // ncols) + 1\n",
    "#     col_pos = (i % ncols) + 1\n",
    "#     # print(f'col: {col}, type: {col_type}, bins: {col_nbins}')\n",
    "\n",
    "#     if col_type == 'float':\n",
    "#         sub_fig = px.histogram(df_test, x=col, histnorm='probability density', nbins=col_nbins).data[0]\n",
    "#         fig.add_trace(sub_fig, row=row, col=col_pos)\n",
    "#     elif col_type == 'str':\n",
    "#         sub_fig = px.bar(df_test, x=col).data[0]\n",
    "#         fig.add_trace(sub_fig, row=row, col=col_pos)\n",
    "    \n",
    "\n",
    "# fig.update_layout(title_text=\"Summary Plots of Test Data\", \n",
    "#                   template=\"plotly_white\",)\n",
    "# fig.write_html(f'{name_dir_export_path_PY}/reg2_df_test_summary_plots.html')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbacbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIAL DEPENDENCIES -- FE21 OLS -- \n",
    "if False: \n",
    "\n",
    "    with open(f'{name_dir_export_path_PY}/reg2_fe_model_coef.json', 'r') as f:\n",
    "        reg2_fe_model_coef = json.load(f)\n",
    "\n",
    "    # call coefficients + build plot\n",
    "    fe21_coef = reg2_fe_model_coef['fe21']['coefficients']\n",
    "    fe21_coef_lin = [fe21_coef[0], fe21_coef[2], fe21_coef[4], fe21_coef[6], fe21_coef[8], ]\n",
    "    fe21_coef_quad = [fe21_coef[1], fe21_coef[3], fe21_coef[5], fe21_coef[7], fe21_coef[9], ]\n",
    "\n",
    "    covariates_fe21 = [\n",
    "        \"elecpri_Rp_kWh\",\n",
    "        \"pvtarif_Rp_kWh\",\n",
    "        \"west_max_flaeche\",\n",
    "        \"south_max_flaeche\",\n",
    "        \"east_max_flaeche\",\n",
    "    ]\n",
    "    ncols = 3\n",
    "    nplots = len (covariates_fe21)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "    fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=covariates_fe21, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "\n",
    "    # addjust fixed effects\n",
    "    agg_methods = {covar: 'mean' for covar in covariates_fe21}\n",
    "    df_plot = df_test.copy()\n",
    "    df_means = df_test.groupby(['BFS_NUMMER', 'year']).agg({**agg_methods, 'TotalPower': 'mean'}).reset_index()\n",
    "    df_plot = df_plot.merge(df_means, on=['BFS_NUMMER', 'year'], suffixes=('', '_mean'))\n",
    "    for covar in covariates_fe21:\n",
    "        df_plot[f'{covar}_fe'] = df_plot[f'{covar}'] - df_plot[f'{covar}_mean']\n",
    "    df_plot['TotalPower'] = df_plot['TotalPower'] - df_plot['TotalPower_mean']\n",
    "\n",
    "\n",
    "    for i, covar in enumerate(covariates_fe21):\n",
    "        x_array = np.linspace(0, round(max(df_test[covar]),0), 200)\n",
    "        y_array = fe21_coef_lin[i] * x_array + fe21_coef_quad[i] * (x_array ** 2) \n",
    "\n",
    "        row = (i // ncols) + 1\n",
    "        col = (i % ncols) + 1\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_array,\n",
    "                y=y_array,\n",
    "                mode='lines',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_plot[f'{covar}'],\n",
    "                y=df_plot['TotalPower'],\n",
    "                mode='markers', \n",
    "                marker=dict(size=2, opacity=0.5),\n",
    "                name=col,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "            )\n",
    "        fig.update_xaxes(title_text= f'{col}', row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "        \n",
    "    for i in range(1, nplots + 1):\n",
    "        row = (i - 1) // ncols + 1\n",
    "        col = (i - 1) % ncols + 1\n",
    "        # fig.update_xaxes(title_text= f'{col}', row=row, col=col)\n",
    "        # fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'FE21 Partial Dependence Plots - {df_train.shape[0]} n_df_train, {df_test.shape[0]} n_df_test / {df_plot.shape[0]} n_df_test_fixedef',  \n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "    fig.write_html(f'{name_dir_export_path_PY}/reg2_fe21_partial_dependence.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ee1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIAL DEPENDENCIES -- FE31 OLS -- \n",
    "if False: \n",
    "    df_train_res3plus = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_train_res3plus.csv')\n",
    "    df_test_res3plus = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test_res3plus.csv')\n",
    "\n",
    "    with open(f'{name_dir_export_path_PY}/reg2_fe_model_coef.json', 'r') as f:\n",
    "        reg2_fe_model_coef = json.load(f)\n",
    "\n",
    "    # call coefficients + build plot\n",
    "    fe31_coef = reg2_fe_model_coef['fe31']['coefficients']\n",
    "    fe31_coef_lin = [fe31_coef[0], fe31_coef[2], fe31_coef[4], fe31_coef[5], fe31_coef[6], fe31_coef[7], fe31_coef[8], fe31_coef[9], \n",
    "                     fe31_coef[11], fe31_coef[13],]\n",
    "\n",
    "    fe31_coef_quad = [ fe31_coef[1], fe31_coef[3], 0, 0, 0, 0, 0, 0, fe31_coef[10], fe31_coef[12], fe31_coef[14]]\n",
    "\n",
    "    covariates_fe31 = [\n",
    "\n",
    "        \"elecpri_Rp_kWh\",\n",
    "        \"pvtarif_Rp_kWh\",\n",
    "        \"GBAUJ\", \n",
    "        \"GKLAS\", \n",
    "        \"GSTAT\", \n",
    "        \"GWAERZH1\", \n",
    "        \"GENH1\", \n",
    "        \"west_max_flaeche\",\n",
    "        \"south_max_flaeche\",\n",
    "        \"east_max_flaeche\",\n",
    "    ]\n",
    "    ncols = 3\n",
    "    nplots = len (covariates_fe31)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "    fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=covariates_fe31, horizontal_spacing=0.1, vertical_spacing=0.15)\n",
    "\n",
    "\n",
    "    # addjust fixed effects\n",
    "    agg_methods = {covar: 'mean' for covar in covariates_fe31}\n",
    "    df_plot = df_test_res3plus.copy()\n",
    "    df_means = df_test_res3plus.groupby(['BFS_NUMMER', 'year']).agg({**agg_methods, 'TotalPower': 'mean'}).reset_index()\n",
    "    df_plot = df_plot.merge(df_means, on=['BFS_NUMMER', 'year'], suffixes=('', '_mean'))\n",
    "    for covar in covariates_fe31:\n",
    "        df_plot[f'{covar}_fe'] = df_plot[f'{covar}'] - df_plot[f'{covar}_mean']\n",
    "    df_plot['TotalPower'] = df_plot['TotalPower'] - df_plot['TotalPower_mean']\n",
    "\n",
    "\n",
    "    for i, covar in enumerate(covariates_fe31):\n",
    "        x_array = np.linspace(0, round(max(df_test_res3plus[covar]),0), 200)\n",
    "        y_array = fe31_coef_lin[i] * x_array + fe31_coef_quad[i] * (x_array ** 2) \n",
    "\n",
    "        row = (i // ncols) + 1\n",
    "        col = (i % ncols) + 1\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_array,\n",
    "                y=y_array,\n",
    "                mode='lines',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_plot[f'{covar}'],\n",
    "                y=df_plot['TotalPower'],\n",
    "                mode='markers', \n",
    "                marker=dict(size=2, opacity=0.5),\n",
    "                name=col,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "    for i in range(1, nplots + 1):\n",
    "        row = (i - 1) // ncols + 1\n",
    "        col = (i - 1) % ncols + 1\n",
    "        fig.update_xaxes(title_text= col, row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Total Power', row=row, col=col)\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'FE21 Partial Dependence Plots - {df_train_res3plus.shape[0]} n_df_train, {df_test_res3plus.shape[0]} n_df_test / {df_plot.shape[0]} n_df_test_fixedef',  \n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "    fig.write_html(f'{name_dir_export_path_PY}/reg2_fe31_partial_dependence.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18887af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIAL DEPENDENCIES -- GAM -- \n",
    "if False:\n",
    "    df_test = pd.read_csv(f'{name_dir_export_path_PY}/reg2_df_test.csv')\n",
    "\n",
    "    features = ['elecpri_Rp_kWh', 'pvtarif_Rp_kWh',\n",
    "                'north_max_flaeche', 'south_max_flaeche',\n",
    "                'east_max_flaeche', 'west_max_flaeche']\n",
    "\n",
    "    ncols = 3\n",
    "    nplots = len(features)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=nrows,\n",
    "        cols=ncols,\n",
    "        subplot_titles=features,\n",
    "    )\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        row = (i // ncols) + 1\n",
    "        col = (i % ncols) + 1\n",
    "\n",
    "        # Generate grid of values for feature i\n",
    "        XX = gam1.generate_X_grid(term=i, n=200)\n",
    "\n",
    "        # Predict partial dependence\n",
    "        pdep = gam1.partial_dependence(term=i, X=XX)\n",
    "\n",
    "        # Scatter raw data for visual context\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_test[feature],\n",
    "                y=df_test['TotalPower'],\n",
    "                mode='markers',\n",
    "                marker=dict(size=2, opacity=0.3),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "\n",
    "        # Add partial dependence line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=XX[:, i],\n",
    "                y=pdep,\n",
    "                mode='lines',\n",
    "                line=dict(color='red'),\n",
    "                name=f'PDP: {feature}',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(title_text=feature, row=row, col=col)\n",
    "        fig.update_yaxes(title_text='Partial Effect', row=row, col=col)\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title_text=f'GAM Partial Dependence Plots ({df_train.shape[0]} train, {df_test.shape[0]} test)',\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    # Save HTML output\n",
    "    fig.write_html(f'{name_dir_export_path_PY}/reg2_gam_partial_dependence.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_optimalpv_rh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
